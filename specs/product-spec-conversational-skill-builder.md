# Conversational Agent Builder

**Created**: 2026-01-25
**Last Updated**: 2026-01-25
**Version**: 2.0
**Status**: Draft

---

## Overview

The Conversational Agent Builder enables completely non-technical users to create, manage, and execute automation agents through natural language conversation with the OmniForge chatbot. Users describe what they want to automate in plain English, and the chatbot intelligently creates an agent that can use one or multiple skills to accomplish the task. The chatbot guides users through connecting integrations (starting with Notion), building the agent logic, testing it, and setting up how it runs (on-demand, scheduled, or triggered by events).

**Agent-First Architecture**: Users create agents, not skills directly. An agent can contain a single skill (for simple automations) or orchestrate multiple skills (for complex workflows). The chatbot determines the optimal skill composition based on user requirements. When creating agents, users can leverage existing public skills from the community library or have the chatbot create custom skills.

This is a premium platform feature that embodies OmniForge's vision of "agents build agents" - the chatbot agent literally creates other agents (with their skill files) that can execute tasks autonomously.

---

## Alignment with Product Vision

This feature directly advances multiple aspects of OmniForge's product vision:

| Vision Principle | How This Feature Delivers |
|------------------|---------------------------|
| **Agents Build Agents** | The chatbot agent creates other agents (with their skills) that execute tasks autonomously |
| **No-Code Interface** | Users describe automations in plain English, never see code or config |
| **Enterprise-Ready** | Three-tier sharing (private/team/public) with proper access controls |
| **Simplicity Over Flexibility** | Public skill library for common patterns, intelligent orchestration for complex workflows |
| **Premium Chatbot Platform** | Core differentiator for premium tier over open-source SDK |

**Strategic Importance**: This feature is the flagship capability that justifies the premium platform. It transforms what would require a developer (creating agents, writing SKILL.md files, orchestrating multi-step workflows, setting up OAuth) into something anyone can do through conversation. The agent-first model means users think in terms of "what I want automated" rather than "how to build automation."

---

## Claude Code Skill Format Compliance

**Critical Requirement**: All skills generated by the conversational agent builder MUST follow [Claude Code's SKILL.md format](https://github.com/Piebald-AI/claude-code-system-prompts) to ensure compatibility, proper progressive disclosure, and adherence to industry standards.

### Why Claude Code Format?

1. **Industry Standard**: Claude Code's skill format is the established standard for LLM agent capabilities
2. **Progressive Disclosure**: Minimal context overhead through three-stage loading (discovery ‚Üí activation ‚Üí reference)
3. **Tool Security**: Standardized `allowed-tools` for restricting agent capabilities
4. **Portability**: Skills work across different OmniForge deployments (SDK and platform)
5. **Community Compatibility**: Users familiar with Claude Code can immediately understand OmniForge skills

### Format Requirements

**SKILL.md Frontmatter**:
- ‚úÖ **Required**: `name` (kebab-case), `description` (one-line, max 80 chars)
- ‚úÖ **Optional**: `allowed-tools` (security), `model`, `context`, `user-invocable`
- ‚úÖ **OmniForge Extensions**: `priority`, `tags`
- ‚ùå **Never Include**: `schedule`, `trigger`, `created-by`, `source`, `author` (these belong in agent.json)

**SKILL.md Content**:
- Natural language instructions in markdown
- Imperative voice ("Do X", "Check Y")
- Error handling guidance
- References to external docs for details

**Progressive Disclosure**:
- SKILL.md: Core instructions (1-10KB)
- docs/: Detailed documentation (loaded on-demand)
- scripts/: Helper scripts (executed, not loaded)
- examples/: Sample data/configs

### Chatbot Responsibilities

The chatbot must:
1. Generate valid YAML frontmatter following Claude Code schema
2. Set appropriate `allowed-tools` based on agent requirements
3. Write clear, specific instructions in natural language
4. Keep SKILL.md concise, referencing external docs for details
5. Never include agent metadata (schedule, trigger, etc.) in SKILL.md

See **Appendix A** for detailed SKILL.md generation guidelines and examples.

---

## Agent-First Architecture

### Core Concept: Agents, Not Skills

Users interact with **agents** as the primary abstraction. An agent is an autonomous automation that accomplishes a specific goal. Under the hood, agents are powered by one or more skills, but users never need to think about skills explicitly.

**User Mental Model**:
```
"I want to create an agent that generates weekly reports"
‚Üí Chatbot creates an agent with whatever skills are needed
‚Üí User sees: "Weekly Reporter" agent (doesn't care about skills inside)
```

### Single-Skill vs Multi-Skill Agents

The chatbot intelligently determines whether an agent needs one skill or multiple skills based on the user's requirements:

| User Request | Agent Composition | Chatbot Decision |
|--------------|-------------------|------------------|
| "Generate weekly reports from Notion" | 1 skill | Simple, single task |
| "Generate reports and post to Slack" | 2 skills (sequential) | Two distinct tasks, output flows between them |
| "Check Notion AND Linear for updates" | 2 skills (parallel) | Independent tasks, run simultaneously |
| "Alert me if deadline is approaching" | 1 skill (conditional logic) | Single task with conditional behavior |

**Key Principle**: Users describe **what** they want, chatbot figures out **how many skills** and **how to orchestrate** them.

### Agent Orchestration Intelligence

When an agent has multiple skills, the chatbot automatically determines orchestration:

#### Sequential Orchestration
Skills run in order, output from one feeds into the next.

```
Example: "Generate report from Notion and post to Slack"

Agent: Weekly Reporter
‚îú‚îÄ Skill 1: Notion Report Generator (runs first)
‚îÇ  ‚îî‚îÄ Output: report.md
‚îî‚îÄ Skill 2: Slack Poster (runs second, uses report.md)
   ‚îî‚îÄ Posts report to #team-updates
```

#### Parallel Orchestration
Skills run independently, no data dependencies.

```
Example: "Check for updates in Notion AND Linear"

Agent: Update Checker
‚îú‚îÄ Skill 1: Notion Scanner (runs concurrently)
‚îî‚îÄ Skill 2: Linear Scanner (runs concurrently)
   ‚îî‚îÄ Both results combined in final output
```

#### Conditional Orchestration
Skills run based on logic conditions.

```
Example: "If project deadline is within 3 days, send Slack alert"

Agent: Deadline Monitor
‚îî‚îÄ Skill: Deadline Checker (checks condition, executes alert if true)
```

**User Experience**: Users never see terms like "sequential" or "parallel." The chatbot explains in plain English:

```
User: "Create an agent that generates reports and posts to Slack"

Bot: "I'll create a 'Weekly Reporter' agent that:
     1. Generates your report from Notion
     2. Posts it to #team-updates in Slack

     When the report is ready, should I post it immediately or wait for your review?"
```

### Public Skill Reusability

When creating an agent, users can leverage existing public skills from the community library:

#### Skill Discovery During Agent Creation

```
User: "Create an agent that generates weekly reports from Notion"

Bot: "I found a public skill called 'Notion Weekly Summary' that does
     something similar (created by @derek, used by 247 people).

     Want to:
     A) Use this existing skill (quick setup, proven to work)
     B) Create a custom skill tailored to your needs"

User: "Use the existing one"

Bot: "Great! I'll create your 'Weekly Reporter' agent using the
     'Notion Weekly Summary' skill. Let me customize it for your databases..."
```

#### Mixing Public and Custom Skills

```
User: "Create an agent that pulls data from Notion and sends a custom email"

Bot: "I can use the public 'Notion Data Extractor' skill for pulling data.

     For the email part, I'll create a custom skill based on your
     email template.

     Sound good?"
```

#### Skill Library Categories

Public skills are organized by:
- **Integration**: Notion, Slack, Linear, GitHub
- **Function**: Reports, Notifications, Sync, Data Processing
- **Popularity**: Most used, trending, recently added
- **Creator**: Community, verified, official

Users can browse the skill library when creating agents, or the chatbot proactively suggests relevant skills.

### Storage Format for Frontend Rendering

Agents use a **dual storage format** to serve both execution and frontend needs:

#### Directory Structure

```
agents/
  weekly-reporter/
    agent.json              ‚Üê Frontend rendering (structured metadata)
    skills/
      notion-report.md      ‚Üê Agent execution (SKILL.md format)
      slack-post.md
  meeting-briefing/
    agent.json
    skills/
      auto-briefing.md
```

#### agent.json Schema

```json
{
  "id": "weekly-reporter",
  "name": "Weekly Reporter",
  "description": "Generates weekly reports from Notion and posts to Slack",
  "status": "active",
  "trigger": "scheduled",
  "schedule": "0 8 30 * * MON",
  "execution_model": "sequential",
  "skills": [
    {
      "id": "notion-report",
      "name": "Notion Weekly Summary",
      "source": "public",
      "author": "@derek",
      "order": 1,
      "config": {
        "databases": ["Client Projects", "Internal Initiatives"],
        "timeframe": "7 days"
      }
    },
    {
      "id": "slack-post",
      "name": "Slack Poster",
      "source": "custom",
      "order": 2,
      "config": {
        "channel": "#team-updates",
        "format": "summary_with_link"
      }
    }
  ],
  "integrations": ["notion", "slack"],
  "created_by": "maya@acme.com",
  "created_via": "conversational-builder",
  "created_at": "2026-01-25T10:30:00Z",
  "version": 1,
  "version_history": [
    {
      "version": 1,
      "timestamp": "2026-01-25T10:30:00Z",
      "changes": "Initial creation"
    }
  ],
  "sharing": {
    "level": "private",
    "shared_with": []
  },
  "usage_stats": {
    "total_runs": 0,
    "last_run": null,
    "success_rate": 0
  }
}
```

#### SKILL.md Format (Execution - Claude Code Standard)

Each skill follows **Claude Code's SKILL.md format** for agent execution:

```markdown
---
# Required fields (Claude Code standard)
name: notion-weekly-summary
description: Generate weekly summary from Notion databases

# Optional fields (Claude Code standard)
allowed-tools:
  - ExternalAPI
  - Read
  - Write
model: claude-sonnet-4-5
context: inherit
user-invocable: false

# OmniForge extensions
tags:
  - notion
  - reporting
---

# Notion Weekly Summary

Generate a formatted weekly summary from specified Notion databases.

## Prerequisites

- Notion API credentials configured
- Target databases accessible
- Valid date range

## Instructions

1. Query specified databases for items updated in last 7 days
2. Group results by specified property (e.g., Client, Project)
3. Sort by priority: At Risk first, then On Track, then Complete
4. For each item, extract: name, status, owner, blockers
5. Format as Markdown bulleted list
6. Write to output file

## Error Handling

- If database not found: Skip and log error
- If API fails: Retry up to 3 times
- If no updates: Return empty report with note

## Reference

- See [notion-api.md](docs/notion-api.md) for API details
```

**Note**: Metadata like `source: public`, `author: derek@acme.com` belongs in `agent.json`, NOT in SKILL.md. SKILL.md contains only execution instructions and tool configuration.

#### Frontend Rendering Strategy

- **Agent List**: Frontend reads `agent.json` files for fast rendering
- **Agent Details**: Shows agent metadata, skill composition, execution history
- **Skill Inspector**: Optionally show skill details (name, source, config)
- **Real-time Updates**: WebSocket updates for execution status

**Frontend Views**:

```
MY AGENTS
‚îú‚îÄ üìä Weekly Reporter (Active, runs Mondays 8:30am)
‚îÇ  ‚îú‚îÄ Status: Last run 2 days ago (success)
‚îÇ  ‚îú‚îÄ Uses: Notion Weekly Summary (public) + Slack Poster (custom)
‚îÇ  ‚îî‚îÄ [Edit] [Pause] [Run Now]
‚îÇ
‚îú‚îÄ üìù Meeting Briefing (Active, event-driven)
‚îÇ  ‚îú‚îÄ Status: Triggered 5 times this week
‚îÇ  ‚îú‚îÄ Uses: Auto Briefing Generator (custom)
‚îÇ  ‚îî‚îÄ [Edit] [Pause] [Settings]
```

Users see agents (their automations), can expand to see which skills are used, execution stats, and controls.

---

## Complex Multi-Skill Use Cases

This section demonstrates how the agent-first architecture handles real-world, complex business processes that require multiple skills working together.

### Use Case 1: Insurance Filing Agent (Healthcare)

**Business Problem**: Hospital administrative staff spend hours manually extracting data from patient bills and filling insurance company forms. Each insurance provider has different forms and requirements.

**Agent Solution**:

```
Agent: Insurance Filing Agent
‚îú‚îÄ Skill 1: Medical Document Extractor (public, sequential order 1)
‚îÇ  ‚îî‚îÄ Extracts: patient_info, charges, diagnosis_codes, provider_details
‚îÇ
‚îú‚îÄ Skill 2: UnitedHealthcare Form Filler (custom, conditional)
‚îÇ  ‚îî‚îÄ Condition: insurance_provider == 'UnitedHealthcare'
‚îÇ  ‚îî‚îÄ Maps extracted data ‚Üí UHC form fields
‚îÇ
‚îú‚îÄ Skill 3: Aetna Form Filler (custom, conditional)
‚îÇ  ‚îî‚îÄ Condition: insurance_provider == 'Aetna'
‚îÇ  ‚îî‚îÄ Maps extracted data ‚Üí Aetna form fields
‚îÇ
‚îú‚îÄ Skill 4: Blue Cross Form Filler (custom, conditional)
‚îÇ  ‚îî‚îÄ Condition: insurance_provider == 'Blue Cross'
‚îÇ  ‚îî‚îÄ Maps extracted data ‚Üí BCBS form fields
‚îÇ
‚îî‚îÄ Skill 5: Quality Checker (custom, sequential order 5)
   ‚îî‚îÄ Validates completeness ‚Üí flags for review or submits
```

**User Experience**:
```
User: "I want to build an agent that files insurance from hospital bills for patients"

Bot: "I can help! Walk me through your process - what steps do you follow?"

User: "I get a patient bill PDF, extract info, then fill the insurance form
       based on which company they use - UHC, Aetna, or Blue Cross"

Bot: "Got it! I found a public skill 'Medical Document Extractor' used by
     500+ hospitals. Want to use it for extracting bill data?"

User: "Yes"

Bot: "Perfect! I'll create custom form fillers for each insurance company.
     Your agent will:
     1. Extract data from the bill
     2. Automatically fill the correct insurance form
     3. Check for missing info before submitting

     When should it run - when new bills are added to Notion?"

User: "Yes, and flag incomplete ones for manual review"

Bot: "Done! Your Insurance Filing Agent will watch for new bills and
     process them automatically."
```

**Orchestration**: Sequential with conditional branching (different forms based on insurance provider)

**Key Features**:
- Public skill reuse (document extraction)
- Custom skills for business-specific logic (form filling)
- Conditional execution (different paths per provider)
- Quality gates (validate before submission)

---

### Use Case 2: PO/Invoice Matching Agent (Finance/Procurement)

**Business Problem**: Finance teams manually compare purchase orders with invoices, checking line items, quantities, and prices. Discrepancies require investigation and slow down payment processing.

**Agent Solution**:

```
Agent: PO/Invoice Matching Agent
‚îú‚îÄ Skill 1A: Purchase Order Parser (public, parallel, order 1)
‚îÇ  ‚îî‚îÄ Extracts: PO number, vendor, line items, agreed prices
‚îÇ
‚îú‚îÄ Skill 1B: Invoice Data Extractor (public, parallel, order 1)
‚îÇ  ‚îî‚îÄ Extracts: Invoice number, vendor, line items, charged prices
‚îÇ  ‚îî‚îÄ Runs in parallel with 1A for speed
‚îÇ
‚îú‚îÄ Skill 2: PO Finder (custom, sequential, order 2)
‚îÇ  ‚îî‚îÄ Matches invoice to PO by PO number
‚îÇ  ‚îî‚îÄ If no match: flag "No PO Found" ‚Üí end
‚îÇ
‚îú‚îÄ Skill 3: Matching Engine (custom, sequential, order 3)
‚îÇ  ‚îî‚îÄ Compares: line items, quantities, prices, totals
‚îÇ  ‚îî‚îÄ Calculates: variance amount, percentage
‚îÇ
‚îî‚îÄ Skill 4: Action Router (custom, conditional, order 4)
   ‚îú‚îÄ IF perfect match (0% variance)
   ‚îÇ  ‚Üí Update Notion: 'Approved for Payment'
   ‚îÇ
   ‚îú‚îÄ IF minor variance (<2%)
   ‚îÇ  ‚Üí Update Notion: 'Review Required'
   ‚îÇ  ‚Üí Slack alert: #purchasing-team
   ‚îÇ
   ‚îú‚îÄ IF major variance (‚â•2%)
   ‚îÇ  ‚Üí Update Notion: 'Rejected'
   ‚îÇ  ‚Üí Slack urgent alert: #purchasing-team
   ‚îÇ
   ‚îî‚îÄ IF no PO found
      ‚Üí Update Notion: 'No PO Found'
      ‚Üí Slack alert: #purchasing-team
```

**User Experience**:
```
User: "Build an agent that matches purchase orders with invoices and flags
       discrepancies"

Bot: "Great! What do you check when matching them?"

User: "Line items, quantities, prices must match. If everything matches,
       approve for payment. Otherwise, notify purchasing team on Slack"

Bot: "I found public skills for extracting PO and invoice data, both used
     by 800+ companies. Want to use them?"

User: "Yes"

Bot: "Perfect! Your agent will:
     1. Extract data from both documents (in parallel for speed)
     2. Compare line items, quantities, prices
     3. If match: approve in Notion
     4. If mismatch: notify Slack with details

     What variance threshold should trigger a review?"

User: "Anything over 2%"

Bot: "Got it! Testing with a real invoice from your Notion...

     Invoice #12345:
     - Found matching PO #9876 ‚úì
     - 4 items match perfectly ‚úì
     - 1 item has 5.9% price increase ‚ö†Ô∏è

     Action: Flagged for review (above 2% threshold)
     Slack message: 'Invoice #12345: Keyboard price $90 vs PO $85 (5.9%)'

     Look good?"

User: "Perfect!"
```

**Orchestration**: Hybrid (parallel extraction + sequential processing + conditional actions)

**Key Features**:
- Parallel skill execution (extract PO and invoice simultaneously)
- Sequential processing (find ‚Üí compare ‚Üí act)
- Complex conditional logic (different actions per variance level)
- Multi-integration (Notion + Slack)
- Real-time testing with actual data

---

### Use Case 3: Customer Onboarding Agent (SaaS/B2B)

**Business Problem**: When new customers sign up, multiple manual steps are required: create accounts, send welcome emails, set up their workspace, assign licenses, and schedule onboarding call.

**Agent Solution**:

```
Agent: Customer Onboarding Agent
‚îú‚îÄ Skill 1: Account Creator (custom, sequential, order 1)
‚îÇ  ‚îî‚îÄ Creates customer account in platform
‚îÇ
‚îú‚îÄ Skill 2A: Welcome Email Sender (public, parallel, order 2)
‚îÇ  ‚îî‚îÄ Sends personalized welcome email
‚îÇ
‚îú‚îÄ Skill 2B: Workspace Setup (custom, parallel, order 2)
‚îÇ  ‚îî‚îÄ Creates default workspace structure
‚îÇ  ‚îî‚îÄ Runs in parallel with email
‚îÇ
‚îú‚îÄ Skill 2C: License Assigner (custom, parallel, order 2)
‚îÇ  ‚îî‚îÄ Assigns licenses based on plan
‚îÇ  ‚îî‚îÄ Runs in parallel with email & workspace
‚îÇ
‚îú‚îÄ Skill 3: Onboarding Scheduler (public, sequential, order 3)
‚îÇ  ‚îî‚îÄ Schedules onboarding call via Calendly
‚îÇ
‚îî‚îÄ Skill 4: Team Notification (custom, sequential, order 4)
   ‚îî‚îÄ Notifies customer success team in Slack
```

**Orchestration**: Mixed (sequential for dependencies, parallel for independent tasks)

---

## B2B2C Deployment Model

### Overview

OmniForge customers can **expose their agents to thousands of their own customers**, enabling a B2B2C model where agents created on the OmniForge platform can be deployed as white-labeled, embeddable automation services that scale to massive end customer bases.

**Scale Requirements**:
- Must support **1,000 to 10,000+ end customers** per Tier 2 organization
- **Incremental deployment**: Start with 10 customers, scale to thousands without redeployment
- **Isolated multi-tenancy**: Each end customer operates independently with their own data/credentials
- **Centralized updates**: Tier 2 customer updates agent logic once, propagates to all end customers

**Key Use Cases**:
- **Data Capture Workflows**: Agents collect structured data from end customers
- **Information Gathering**: Standardized data collection across thousands of customers
- **Automated Processing**: Consistent workflows applied at scale

**Example Scenarios**:

1. **Hospital Chain ‚Üí 2,500 Hospitals** (Healthcare Data Capture)
   - Hospital chain creates "Insurance Filing Agent"
   - Deploys to 2,500 hospitals nationwide
   - Each hospital submits insurance claims via agent
   - Chain aggregates data for analytics and compliance
   - Incremental onboarding: 50 hospitals/month over 5 years

2. **Accounting Firm ‚Üí 5,000 SMB Clients** (Financial Data Collection)
   - Accounting firm creates "Expense Reporting Agent"
   - Offers it as a value-added service to 5,000 SMB clients
   - Each client submits expenses via white-labeled portal
   - Firm processes all client data centrally
   - Clients access via branded portal (firm's domain)

3. **Insurance Company ‚Üí 50,000 Policyholders** (Claims Processing)
   - Insurance company creates "Claims Submission Agent"
   - Embeds it in customer portal for 50,000 policyholders
   - Policyholders submit claims via standardized workflow
   - Agent validates data and routes to processing
   - Company tracks submission patterns and fraud indicators

4. **Survey Platform ‚Üí 100,000 Respondents** (Data Collection)
   - Research firm creates "Survey Response Agent"
   - Deploys to 100,000 survey respondents
   - Each respondent submits via personalized link
   - Agent captures structured responses
   - Firm analyzes aggregated data

### Architecture

```
OmniForge Platform (Tier 1)
‚îî‚îÄ Customer Organization (Tier 2)
   ‚îú‚îÄ Creates agents
   ‚îú‚îÄ Configures white-labeling
   ‚îî‚îÄ Deploys to End Customers (Tier 3)
      ‚îú‚îÄ End Customer A (isolated tenant)
      ‚îú‚îÄ End Customer B (isolated tenant)
      ‚îî‚îÄ End Customer C (isolated tenant)
```

### Key Capabilities

#### 1. Agent Publishing for End Customers

**Publishing Flow**:
```
User: "I want to make my Insurance Filing Agent available to our
       hospital network"

Bot: "Great! I'll help you publish this agent for your customers.

     DEPLOYMENT OPTIONS:

     A) White-Labeled Portal
        Your hospitals access agents through a branded portal
        (your logo, colors, domain)

     B) Embedded Widget
        Embed agent in your existing hospital management system

     C) API Access
        Your hospitals integrate via API

     Which deployment model?"

User: "White-labeled portal"

Bot: "Perfect! Let me set up your portal:

     BRANDING:
     - Portal URL: agents.yourhospitalchain.com (custom domain)
     - Logo: [upload your logo]
     - Colors: [customize theme]
     - Name: 'HospitalChain Automation Hub'

     AGENT CONFIGURATION:
     - Agent: Insurance Filing Agent
     - Available to: All hospitals in your network
     - Each hospital uses their own credentials (isolated)

     USAGE TRACKING:
     - Track which hospitals use the agent
     - Monitor execution success rates
     - View usage analytics per hospital

     Ready to publish?"

User: "Yes"

Bot: "Published! Your Insurance Filing Agent is now available at:
     agents.yourhospitalchain.com

     Next steps:
     1. Invite hospitals via email (I can send invites)
     2. Each hospital completes onboarding (connects their Notion, etc.)
     3. They start using the agent

     Want me to send invites now?"
```

#### 2. Multi-Tenant Isolation

Each end customer (Tier 3) operates in an isolated environment:

**Data Isolation**:
- End customer A's data never accessible to end customer B
- Separate credential storage per end customer
- Agent execution logs isolated per tenant

**Configuration Isolation**:
- End customers can customize agent parameters
- Customizations don't affect other tenants
- Version updates managed centrally by Tier 2 customer

**Example**:
```
Hospital Chain (Tier 2) deploys "Insurance Filing Agent"

Hospital A (Tier 3):
- Uses their own Notion workspace
- Configured for UnitedHealthcare + Aetna
- Processes 500 bills/month

Hospital B (Tier 3):
- Uses their own Notion workspace
- Configured for Blue Cross only
- Processes 200 bills/month

Both use the same agent logic, but completely isolated data and configs.
```

#### 3. White-Labeling & Branding

Tier 2 customers can fully brand the agent experience:

**Portal Customization**:
```json
{
  "branding": {
    "portal_url": "agents.yourhospitalchain.com",
    "company_name": "HospitalChain Automation Hub",
    "logo_url": "https://cdn.yourhospitalchain.com/logo.png",
    "theme": {
      "primary_color": "#2563eb",
      "secondary_color": "#1e40af",
      "font": "Inter"
    },
    "support_email": "support@yourhospitalchain.com",
    "documentation_url": "https://docs.yourhospitalchain.com/agents"
  }
}
```

**Embedded Widget**:
```html
<!-- Hospital embeds agent in their system -->
<script src="https://omniforge.ai/embed.js"></script>
<div id="insurance-agent"
     data-org="hospital-chain-123"
     data-agent="insurance-filing"
     data-theme="custom"></div>
```

**API Access**:
```python
# Hospital integrates via API
from omniforge_client import OmniForge

client = OmniForge(
    org_id="hospital-chain-123",
    api_key="hosp_a_secret_key"  # Unique per hospital
)

# Trigger agent
result = client.agents.run(
    agent_id="insurance-filing",
    input={"bill_id": "notion://page/12345"}
)
```

#### 4. Usage Tracking & Analytics

Tier 2 customers get visibility into how their end customers use agents:

**Dashboard Metrics**:
- Total agent runs per end customer
- Success/failure rates
- Average execution time
- Integration usage (which APIs called)
- Error patterns

**Billing Integration**:
- Track usage for metering
- Support usage-based pricing models
- Export usage data for billing systems

**Example Dashboard**:
```
Insurance Filing Agent - Usage (Last 30 Days)

Total End Customers: 50 hospitals
Total Executions: 12,450
Success Rate: 94.2%

Top Users:
1. St. Mary's Hospital - 1,200 executions (96% success)
2. General Medical Center - 980 executions (92% success)
3. County Hospital - 750 executions (95% success)

Common Errors:
- Missing diagnosis code: 3.2% of runs
- Invalid insurance provider: 2.1% of runs
- Notion connection expired: 0.5% of runs
```

#### 5. Centralized Management & Updates

Tier 2 customers manage agents centrally for all end customers:

**Version Control**:
```
User: "I want to update the Insurance Filing Agent to support Cigna"

Bot: "I'll add Cigna support. This will update the agent for all 50 hospitals.

     NEW VERSION: 2.0
     - Added Cigna form filler skill
     - All existing functionality preserved

     ROLLOUT OPTIONS:
     A) Immediate rollout (all hospitals get update now)
     B) Staged rollout (test with 5 hospitals, then expand)
     C) Opt-in (hospitals choose when to upgrade)

     Which approach?"

User: "Staged rollout"

Bot: "Great! Select 5 hospitals for initial testing:
     [Shows list of 50 hospitals with usage stats]"
```

**Monitoring & Support**:
- Central error monitoring across all tenants
- Proactive alerts when end customers hit issues
- Aggregate analytics for agent optimization

#### 6. End Customer Onboarding

When Tier 2 publishes an agent, end customers go through a guided onboarding:

**Onboarding Flow**:
```
1. End customer receives invite email
   "HospitalChain has created an automation to help you file insurance..."

2. End customer accesses white-labeled portal
   [HospitalChain branded UI, not OmniForge branding]

3. Chatbot guides setup
   Bot: "Welcome to HospitalChain Automation Hub! I'll help you set up
         the Insurance Filing Agent for your hospital.

         First, let's connect to your Notion workspace..."

4. End customer connects integrations
   [OAuth flows for Notion, etc.]

5. End customer customizes configuration
   Bot: "Which insurance companies do you work with?"
   User: "UnitedHealthcare and Aetna"
   Bot: "Got it! Your agent will handle both..."

6. Test run
   Bot: "Let's test with one of your bills to make sure it works..."

7. Activation
   Bot: "You're all set! The agent will now process bills automatically."
```

#### 7. Massive Scale & Data Aggregation

The platform must support deployments that scale to thousands of end customers with efficient data aggregation capabilities.

**Scale Architecture**:

```
Tier 2 Customer: Insurance Company
‚îî‚îÄ Published Agent: Claims Submission Agent
   ‚îú‚îÄ End Customer 1 (Policyholder) ‚Üí Submits claim data
   ‚îú‚îÄ End Customer 2 (Policyholder) ‚Üí Submits claim data
   ‚îú‚îÄ End Customer 3 (Policyholder) ‚Üí Submits claim data
   ‚îú‚îÄ ... (thousands more)
   ‚îî‚îÄ End Customer 50,000 (Policyholder) ‚Üí Submits claim data

Data Flow:
1. Each end customer submits data via agent
2. Agent validates and processes data in isolation
3. Tier 2 customer aggregates data across all end customers
4. Analytics, reporting, compliance tracking at scale
```

**Incremental Deployment**:

Tier 2 customers don't need to onboard all end customers at once:

```
Month 1: Deploy to 100 end customers (pilot)
Month 2: Deploy to 500 end customers (early adopters)
Month 3-6: Deploy to 2,000 end customers (gradual rollout)
Month 7-12: Deploy to 10,000 end customers (full scale)

Platform handles growth seamlessly without reconfiguration
```

**Data Capture Workflows**:

Agents can be designed specifically for data collection at scale:

| Use Case | Tier 2 Customer | End Customers | Data Captured |
|----------|----------------|---------------|---------------|
| **Insurance Claims** | Insurance Company | 50,000 policyholders | Claims, medical records, photos |
| **Expense Reporting** | Accounting Firm | 5,000 SMBs | Receipts, invoices, categorizations |
| **Survey Responses** | Research Firm | 100,000 respondents | Survey answers, demographics |
| **Patient Intake** | Hospital Network | 10,000 patients/month | Medical history, symptoms, insurance |
| **Vendor Onboarding** | Enterprise | 1,000 vendors | W-9 forms, contracts, certifications |

**Aggregation & Analytics**:

Tier 2 customers get aggregated views across all end customers:

```
Dashboard: Claims Submission Agent (Insurance Company)

Total End Customers: 50,000 policyholders
Active Submissions Today: 1,247 claims
Completion Rate: 94.3%

Top Data Points Collected:
- Incident details: 1,247
- Medical records: 1,180
- Photos uploaded: 3,412
- Estimated cost: $2.4M total

Common Issues:
- Missing documentation: 5.2% of submissions
- Invalid policy numbers: 1.3% of submissions

Processing Status:
- Auto-approved: 78% (threshold met, no red flags)
- Pending review: 16% (missing info or high value)
- Rejected: 6% (validation failed)
```

**Performance Requirements for Scale**:

| Metric | Target | Rationale |
|--------|--------|-----------|
| **End Customers per Agent** | 100,000+ | Support enterprise deployments |
| **Concurrent Executions** | 1,000+ simultaneous | Peak load handling |
| **Data Isolation Latency** | <100ms | Fast tenant lookup |
| **Incremental Onboarding** | 1,000/day | Gradual rollout support |
| **Aggregation Query Speed** | <2s for 10,000 customers | Dashboard performance |
| **Storage per End Customer** | 100MB average | Cost efficiency at scale |

**Cost Model for Scale**:

Tier 2 customers pay based on usage:

```
Pricing Tiers:
- 1-100 end customers: $X/customer/month
- 101-1,000 end customers: $Y/customer/month (volume discount)
- 1,001-10,000 end customers: $Z/customer/month (enterprise pricing)
- 10,001+ end customers: Custom pricing

Execution-based: $W per 1,000 agent executions
Storage: $S per GB/month (aggregated data)
```

#### 8. Testing & Incremental Change Management

**Critical Requirement**: When an agent is published to thousands of end customers, changes must be tested and rolled out incrementally to prevent breaking changes at scale.

##### Testing Flow (Pre-Deployment)

**Phase 1: Development Testing (Tier 2 Customer)**

```
User: "I want to update the Insurance Filing Agent to support a new insurance provider"

Bot: "I'll add support for Cigna. Before deploying to your 2,500 hospitals,
     let's test thoroughly.

     TESTING ENVIRONMENTS:

     1. SANDBOX (Just you)
        Test with your own data, won't affect any hospitals

     2. PILOT GROUP (5-10 hospitals)
        Select hospitals to test with real data

     3. STAGED ROLLOUT (10% ‚Üí 50% ‚Üí 100%)
        Gradually deploy to all hospitals

     Start with sandbox testing?"

User: "Yes"

Bot: "Running sandbox test...

     ‚úì Extracted patient data
     ‚úì Filled Cigna form
     ‚úì Validated all fields

     Test Result: SUCCESS

     Ready to test with pilot hospitals?"

User: "Yes, use Springfield Hospital and Metro Medical for pilot"

Bot: "I'll deploy version 2.0 to Springfield and Metro Medical only.

     Other 2,498 hospitals will continue using version 1.0.

     I'll monitor for 48 hours. If success rate stays above 95%,
     I'll recommend wider rollout.

     Deploy to pilot?"
```

**Phase 2: Pilot Testing (5-10 End Customers)**

```
After 48 hours:

Bot: "PILOT TEST RESULTS (v2.0 - Cigna support)

     Springfield Hospital:
     - 47 claims processed
     - 46 successful (97.9%)
     - 1 failed (missing Cigna group number)

     Metro Medical:
     - 32 claims processed
     - 31 successful (96.9%)
     - 1 failed (same issue)

     ISSUE DETECTED:
     Cigna requires 'Group Number' field that we're not collecting.

     OPTIONS:
     A) Fix the issue, re-test pilot
     B) Rollback pilot to v1.0
     C) Deploy anyway (not recommended)

     What would you like to do?"

User: "Fix the issue"

Bot: "I'll update the agent to collect Group Number for Cigna claims.

     Testing in sandbox...
     ‚úì Updated Cigna form to include Group Number
     ‚úì Sandbox test passed

     Re-deploy to pilot hospitals?"

User: "Yes"

Bot: "Deployed v2.1 to Springfield and Metro Medical.
     Monitoring for another 24 hours..."
```

**Phase 3: Staged Rollout**

```
After successful pilot:

Bot: "PILOT SUCCESS! (v2.1 - Cigna support)

     72 hours of testing:
     - 156 claims processed
     - 154 successful (98.7%)
     - 2 failed (unrelated Notion connection issues)

     Ready for staged rollout to all 2,500 hospitals?

     ROLLOUT STRATEGY:

     Stage 1 (10%): 250 hospitals - Deploy Mon, monitor 48hrs
     Stage 2 (50%): 1,250 hospitals - Deploy Wed, monitor 48hrs
     Stage 3 (100%): All 2,500 hospitals - Deploy Fri

     If any stage fails (success rate < 95%), auto-rollback.

     Proceed with staged rollout?"

User: "Yes"

Bot: "Starting Stage 1: Deploying v2.1 to 250 hospitals...

     I'll select hospitals with highest usage for early feedback.

     You'll get alerts if:
     - Success rate drops below 95%
     - Error rate spikes
     - Any hospital reports issues

     Stage 1 deployment complete. Monitoring..."
```

##### Rollout Strategies

**1. Canary Deployment (Lowest Risk)**
```
Version 2.0 rollout:
- Day 1: 1% of end customers (25 hospitals)
- Day 3: 5% of end customers (125 hospitals)
- Day 5: 10% of end customers (250 hospitals)
- Day 7: 25% of end customers (625 hospitals)
- Day 10: 50% of end customers (1,250 hospitals)
- Day 14: 100% of end customers (2,500 hospitals)

Automatic rollback if success rate < 95% at any stage
```

**2. Blue-Green Deployment**
```
- Version 1.0 (Blue): Running on 100% of end customers
- Version 2.0 (Green): Deploy to parallel infrastructure, test with synthetic traffic
- Switch: Gradually migrate end customers from Blue ‚Üí Green
- Rollback: Instant switch back to Blue if issues detected
```

**3. A/B Testing**
```
Split end customers into groups:
- Group A (50%): Continue with v1.0
- Group B (50%): Upgrade to v2.0

Compare metrics:
- Success rate
- Execution time
- Error types
- User satisfaction

If B outperforms A ‚Üí deploy v2.0 to all
If A better than B ‚Üí rollback B to v1.0
```

**4. Feature Flags (Granular Control)**
```
Deploy v2.0 with Cigna support disabled by default

Enable for specific end customers:
- Hospital A: Cigna enabled ‚úì
- Hospital B: Cigna enabled ‚úì
- Hospital C: Cigna disabled (uses old version)

Gradually enable Cigna support as confidence grows
```

##### Rollback Mechanisms

**Automatic Rollback Triggers**:
```json
{
  "rollback_rules": {
    "success_rate_threshold": 95,
    "error_rate_spike": "20% increase over baseline",
    "execution_time_spike": "2x baseline",
    "end_customer_complaints": "3 or more in 1 hour"
  }
}
```

**Manual Rollback**:
```
User: "Rollback the Cigna update, we're getting too many errors"

Bot: "Rolling back 'Insurance Filing Agent' for all 2,500 hospitals...

     ROLLBACK PLAN:
     - Reverting to v1.0 (stable version)
     - Current v2.1 users: 1,250 hospitals (Stage 1 & 2)
     - Rollback time: ~5 minutes

     v2.1 will remain active for pilot hospitals (2) for testing.

     Confirm rollback?"

User: "Yes"

Bot: "Rollback complete!

     STATUS:
     - 1,250 hospitals reverted to v1.0 ‚úì
     - 2 pilot hospitals still on v2.1 (for debugging)
     - 1,248 hospitals never upgraded (still on v1.0)

     All hospitals now stable on v1.0.

     Would you like to review v2.1 errors before next deployment?"
```

##### Version Management for Published Agents

**Version Strategy**:
```
Agent: Insurance Filing Agent (Published to 2,500 hospitals)

v1.0 (Stable) - 2,498 hospitals
‚îú‚îÄ Features: UHC, Aetna, Blue Cross
‚îî‚îÄ Status: Production

v2.0 (Pilot) - 2 hospitals
‚îú‚îÄ Features: UHC, Aetna, Blue Cross, Cigna (new)
‚îú‚îÄ Status: Pilot testing
‚îî‚îÄ Pilot hospitals: Springfield, Metro Medical

v2.1 (Development) - 0 hospitals
‚îú‚îÄ Features: v2.0 + Group Number fix
‚îú‚îÄ Status: Sandbox only
‚îî‚îÄ Ready for pilot re-deployment
```

**Conversational Version Control**:
```
User: "What version is each hospital using?"

Bot: "VERSION DISTRIBUTION (Insurance Filing Agent)

     v1.0 (Stable): 2,498 hospitals (99.9%)
     v2.0 (Pilot): 2 hospitals (0.1%)

     VERSIONS AVAILABLE:
     - v1.0: UHC, Aetna, Blue Cross
     - v2.0: + Cigna support (pilot)
     - v2.1: + Group Number fix (sandbox)

     Want to see which hospitals are on which version?"

User: "Yes, show hospitals on v2.0"

Bot: "HOSPITALS ON v2.0 (Pilot):
     1. Springfield Hospital
     2. Metro Medical Center

     Both deployed 3 days ago for pilot testing."
```

##### Impact Analysis Before Deployment

**Pre-Deployment Checks**:
```
User: "Deploy Cigna update to all hospitals"

Bot: "Let me analyze the impact first...

     IMPACT ANALYSIS:

     Affected End Customers: 2,500 hospitals
     Current Version: v1.0
     New Version: v2.1

     CHANGES:
     + Added Cigna support
     + Added Group Number field
     ~ Modified form validation logic

     RISK ASSESSMENT:
     - Backward compatibility: ‚úì No breaking changes
     - Data migration needed: ‚úó None required
     - Integration changes: ‚úì New Cigna API integration
     - Estimated success rate: 98.5% (based on pilot)

     AFFECTED DATA:
     - Hospitals using Cigna: ~400 (16%)
     - Hospitals not using Cigna: ~2,100 (84%) - no impact

     RECOMMENDATION:
     Low risk deployment. Suggest staged rollout.

     Proceed with deployment?"
```

##### Monitoring & Alerts During Rollout

**Real-Time Monitoring**:
```
Stage 1 Rollout in Progress (250 hospitals):

LIVE METRICS (updating every 30 seconds):
- Deployed: 250/250 hospitals ‚úì
- Agent executions: 127 (last hour)
- Success rate: 96.8% ‚úì (threshold: 95%)
- Avg execution time: 3.2s (baseline: 3.1s) ‚úì
- Errors: 4 (3.2%) - within normal range ‚úì

ERROR BREAKDOWN:
- Notion connection timeout: 2
- Missing patient data: 1
- Cigna API rate limit: 1

ALERT STATUS: ‚úÖ All systems normal

Next check in 30 seconds...
```

**Alert Notifications**:
```
‚ö†Ô∏è ALERT: Stage 2 Rollout Issue

Agent: Insurance Filing Agent
Stage: 2 (deploying to 1,250 hospitals)
Issue: Success rate dropped to 91.2% (threshold: 95%)

ERROR SPIKE DETECTED:
- Cigna API rate limit errors: 47 in last 10 mins
- Root cause: Exceeded Cigna API quota (500 req/hour)

AUTOMATIC ACTION TAKEN:
- Paused Stage 2 rollout (deployed to 623/1,250 hospitals)
- Remaining 627 hospitals NOT upgraded (still on v1.0)

RECOMMENDATIONS:
A) Increase Cigna API quota and resume
B) Implement request throttling and resume
C) Rollback Stage 2 to v1.0

What would you like to do?
```

##### Testing User Story

**US-B2B2C-TEST-1: Staged Rollout**
**As** a Tier 2 customer (hospital chain admin)
**I want** to deploy agent updates incrementally with automatic rollback
**So that** I don't break automation for 2,500 hospitals at once

**Acceptance Criteria**:
- Test in sandbox before any deployment
- Select pilot hospitals for initial testing (5-10)
- Monitor pilot for configurable duration (24-72 hours)
- Staged rollout with automatic pause on errors
- Automatic rollback if success rate drops below threshold
- Real-time monitoring dashboard during rollout
- Version control: multiple versions live simultaneously
- Ability to manually rollback at any stage

##### End Customer Communication During Updates

**Notification Strategy**:
```
User: "I'm deploying v2.1 to all 2,500 hospitals. Should I notify them?"

Bot: "I recommend notifying hospitals before major updates.

     NOTIFICATION OPTIONS:

     A) Email Announcement (recommended)
        Send 48 hours before deployment
        Explains what's changing and when

     B) In-App Banner
        Display banner when hospitals access portal
        'New Cigna support coming soon'

     C) No Notification
        Deploy silently (backward compatible changes only)

     For v2.1 (Cigna support), I recommend Option A + B
     since it adds new functionality.

     Send notifications?"

User: "Yes, both email and in-app banner"

Bot: "NOTIFICATION PREVIEW:

     EMAIL SUBJECT:
     New Insurance Provider Support - Cigna Claims Now Available

     EMAIL BODY:
     Dear [Hospital Name],

     We're excited to announce that your Insurance Filing Agent
     now supports Cigna claims!

     WHAT'S NEW:
     - File Cigna claims directly through the portal
     - Automatic Group Number validation
     - Same easy workflow you're familiar with

     WHEN:
     - Pilot: 2 hospitals (testing now)
     - Your hospital: Rolling out Feb 5-12

     NO ACTION REQUIRED:
     The update happens automatically. You'll see Cigna as
     an option when filing new claims.

     Questions? Contact support@hospitalchain.com

     ---

     Send to all 2,500 hospitals?"

User: "Yes, send it"

Bot: "Emails queued! Sending to 2,500 hospitals over next hour.
     In-app banner will activate 48 hours before each hospital's
     deployment window.

     Notification status:
     - Emails sent: 0/2,500 (in progress)
     - Banner scheduled: ‚úì"
```

**Version-Specific End Customer Experience**:
```
Hospital on v1.0 sees:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Insurance Filing Portal             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚ÑπÔ∏è Coming Soon: Cigna Support      ‚îÇ
‚îÇ    Deploying to your hospital Feb 8 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

File New Claim:
‚óã UnitedHealthcare
‚óã Aetna
‚óã Blue Cross

---

Hospital on v2.1 sees:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Insurance Filing Portal             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚ú® New: Cigna support now available!‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

File New Claim:
‚óã UnitedHealthcare
‚óã Aetna
‚óã Blue Cross
‚óã Cigna (NEW!)
```

##### Deployment Governance & Approvals

For enterprise Tier 2 customers managing thousands of end customers:

```
User: "I want to require approval before deploying to production"

Bot: "I'll set up deployment approvals for your organization.

     APPROVAL WORKFLOW:

     1. Developer creates/tests agent update in sandbox
     2. Request deployment ‚Üí triggers approval workflow
     3. Approver reviews:
        - Change summary
        - Impact analysis
        - Test results
        - Pilot performance
     4. Approver approves/rejects
     5. If approved ‚Üí staged rollout begins

     WHO CAN APPROVE DEPLOYMENTS?
     (Select users with approval authority)"

User: "Only VP of Operations and CTO can approve"

Bot: "Got it! Deployment approvals configured:

     APPROVAL REQUIRED FOR:
     - Production deployments (all 2,500 hospitals)
     - Staged rollouts >10% of end customers

     NO APPROVAL NEEDED FOR:
     - Sandbox testing
     - Pilot testing (<10 hospitals)

     APPROVERS:
     - VP of Operations (jane@hospitalchain.com)
     - CTO (mike@hospitalchain.com)

     Any deployment request will email both approvers.
     Need 1 approval to proceed."
```

##### Change Log for End Customers

**Automatic Change Documentation**:
```
What's New in Insurance Filing Agent (v2.1)

üìÖ Deployed: February 12, 2026

‚ú® NEW FEATURES:
- Cigna Claims Support
  File Cigna insurance claims directly through the portal

üîß IMPROVEMENTS:
- Added Group Number field for Cigna claims
- Improved validation error messages
- Faster claim processing (avg 3.1s ‚Üí 2.8s)

üêõ BUG FIXES:
- Fixed issue where UHC claims with special characters failed
- Resolved Notion connection timeout for large uploads

---

Previous Updates:
v2.0 (Jan 25, 2026) - Added Blue Cross support
v1.5 (Dec 10, 2025) - Performance improvements
v1.0 (Nov 1, 2025) - Initial release
```

### B2B2C User Stories

#### US-B2B2C-1: Publish Agent to End Customers
**As** a Tier 2 customer (hospital chain admin)
**I want** to publish my Insurance Filing Agent to my network of hospitals
**So that** all hospitals can benefit from automation without building it themselves

**Acceptance Criteria**:
- Configure white-labeling (logo, colors, domain)
- Select which agents to publish
- Choose deployment model (portal, embed, API)
- Set up usage tracking
- Send onboarding invites to end customers

---

#### US-B2B2C-2: End Customer Onboarding
**As** a Tier 3 end customer (individual hospital)
**I want** to easily set up and use agents provided by my parent organization
**So that** I can automate work without technical expertise

**Acceptance Criteria**:
- Access white-labeled portal (no OmniForge branding)
- Guided setup via chatbot
- Connect my own integrations (isolated from other hospitals)
- Test agent before activation
- Clear documentation and support

---

#### US-B2B2C-3: Centralized Agent Updates
**As** a Tier 2 customer
**I want** to update agents centrally for all my end customers
**So that** improvements roll out automatically without manual intervention

**Acceptance Criteria**:
- Edit agent in one place
- Choose rollout strategy (immediate, staged, opt-in)
- Preview impact before deployment
- Monitor adoption of new version

---

#### US-B2B2C-4: Usage Analytics
**As** a Tier 2 customer
**I want** to see how my end customers use agents
**So that** I can optimize agents and support usage-based pricing

**Acceptance Criteria**:
- Dashboard showing usage per end customer
- Success/failure metrics
- Error analysis
- Export data for billing

---

### B2B2C Storage Structure

```
organizations/
  hospital-chain-123/              ‚Üê Tier 2 customer
    agents/
      insurance-filing/
        agent.json                 ‚Üê Master agent configuration
        skills/
          medical-doc-extractor.md
          uhc-form-filler.md
        deployment.json            ‚Üê B2B2C deployment config

    end-customers/                 ‚Üê Tier 3 tenants
      st-marys-hospital/
        credentials/               ‚Üê Isolated credentials
          notion-oauth.enc
        agent-instances/
          insurance-filing/
            config.json            ‚Üê Hospital-specific config
            execution-logs/

      general-medical/
        credentials/
          notion-oauth.enc
        agent-instances/
          insurance-filing/
            config.json
            execution-logs/
```

**deployment.json**:
```json
{
  "agent_id": "insurance-filing",
  "published": true,
  "deployment_type": "white_label_portal",
  "branding": {
    "portal_url": "agents.hospitalchain.com",
    "company_name": "HospitalChain Automation Hub",
    "logo_url": "https://cdn.hospitalchain.com/logo.png",
    "theme": {
      "primary_color": "#2563eb",
      "font": "Inter"
    }
  },
  "end_customers": [
    {
      "id": "st-marys-hospital",
      "name": "St. Mary's Hospital",
      "status": "active",
      "onboarded_at": "2026-01-20T10:00:00Z",
      "agent_version": "2.0"
    },
    {
      "id": "general-medical",
      "name": "General Medical Center",
      "status": "active",
      "onboarded_at": "2026-01-22T14:30:00Z",
      "agent_version": "2.0"
    }
  ],
  "usage_tracking": {
    "enabled": true,
    "metrics": ["runs", "success_rate", "execution_time"],
    "billing_integration": "stripe"
  }
}
```

---

## User Personas

### Primary Users

#### Maya - The Operations Manager

**Role**: Operations Manager at a 50-person marketing agency

**Technical Ability**: Uses Notion daily, can create formulas in spreadsheets, but has never written code or used APIs

**Context**:
- Manages project tracking in Notion across 15 client accounts
- Spends 3+ hours weekly on repetitive status updates and report generation
- Has asked IT for automation help but they're backlogged for months
- Tried Zapier once but got stuck on "webhook URLs" and gave up

**Goals**:
- Automate weekly status report creation from Notion project boards
- Get notified when project deadlines are approaching
- Sync meeting notes to the right Notion pages automatically

**Pain Points**:
- "I know exactly what I want automated, I just don't know how to make it happen"
- "Every automation tool assumes I know what an API is"
- "I don't have time to learn a new tool, I just need this to work"

**Key Quote**: "I want to tell the computer what to do in normal words and have it figure out the technical stuff."

**What Maya Needs**:
- Plain English agent creation with zero technical jargon
- Step-by-step guidance with confirmation at each stage
- Easy way to test that agents work before relying on them
- Clear explanations when something goes wrong

---

#### Derek - The Team Lead

**Role**: Engineering Team Lead at a SaaS startup

**Technical Ability**: Understands technical concepts but doesn't want to spend time coding automations; can review code but prefers not to write it

**Context**:
- Team uses Notion for documentation, Linear for issue tracking, Slack for communication
- Wants to standardize team workflows but doesn't have time to build tooling
- Has some Python scripts that he wrote years ago but can't maintain them

**Goals**:
- Create agents that his whole team can use
- Share useful automations across the organization
- Customize agents when team needs change
- Potentially deploy agents to partner organizations (B2B2C)

**Pain Points**:
- "I could probably figure out how to do this myself, but I have higher priorities"
- "I want to create something once and have the whole team benefit"
- "When I need to change something, I don't want to dig through code"

**Key Quote**: "I want to describe the workflow and have it just exist. If I need to tweak it later, I want to describe the change, not edit config files."

**What Derek Needs**:
- Efficient agent creation without excessive hand-holding
- Team sharing with proper access controls
- Conversational agent editing with visual diffs
- Automatic versioning so changes can be reviewed
- Ability to publish agents to external customers (white-labeled)

---

#### Sandra - The Executive Assistant

**Role**: Executive Assistant to CEO at a manufacturing company

**Technical Ability**: Expert with office productivity tools, no programming knowledge, apprehensive about "breaking things"

**Context**:
- Manages CEO's calendar, meeting prep, and follow-ups
- Uses Notion as a central hub for all executive documentation
- Currently copies information between systems manually

**Goals**:
- Automatically prepare meeting briefings in Notion before each meeting
- Capture action items from meeting notes and track them
- Never miss a follow-up or deadline

**Pain Points**:
- "I'm afraid of setting up automation wrong and embarrassing my boss"
- "I need to understand exactly what will happen before I commit"
- "If something goes wrong, I need to know immediately and be able to fix it"

**Key Quote**: "I need to trust this completely before I'll use it for anything important."

**What Sandra Needs**:
- Preview of exactly what an agent will do before running it
- Safe testing environment that can't affect real data
- Clear confirmation before any action is taken
- Immediate notification if something fails

---

### Secondary Users

#### IT Administrator (Governance)
- Needs visibility into what agents exist across the organization
- Must be able to disable problematic agents quickly
- Requires audit logs of agent executions
- Manages B2B2C deployments (which agents are published to end customers)

#### Power User (Agent Curator)
- Discovers and adapts agents from the community library
- Customizes shared agents for team-specific needs
- Contributes refined agents and public skills back to the community
- May publish agents to external customers (B2B2C)

#### B2B2C Customer (Tier 3 End User)
- Receives agents from parent organization (hospital chain, accounting firm, etc.)
- Uses agents through white-labeled portal
- No direct interaction with OmniForge brand
- Expects simple onboarding and ongoing support from Tier 2 organization

---

## Problem Statement

### The Automation Gap

Non-technical users know exactly what they want to automate. They can describe their workflows perfectly:

> "Every Monday, I need to look at all our active projects in Notion, check which ones have updates from last week, and create a summary document for my leadership meeting."

But translating this into reality requires:
- Understanding OAuth flows and API authentication
- Writing configuration files in specific formats (YAML, JSON, Markdown frontmatter)
- Setting up webhooks, cron jobs, or event listeners
- Orchestrating multi-step workflows
- Debugging when things go wrong
- Maintaining scripts as APIs change

**The result**: Valuable automations never get built, or require developer time that could be spent on product work.

**Additional B2B2C Gap**: Organizations that create valuable automations have no easy way to share them with customers. Hospital chains, accounting firms, and SaaS companies want to offer automation-as-a-service but face barriers:
- No white-labeling capabilities in existing tools
- Complex multi-tenant setup required
- Difficult to manage updates across customer base
- Limited usage tracking for billing/analytics

### Why Existing Solutions Fail for Non-Technical Users

| Solution | Why It Fails |
|----------|--------------|
| **Zapier/Make** | Assumes understanding of triggers, actions, webhooks; visual interface is still technical |
| **Custom Scripts** | Requires programming knowledge |
| **Notion Automations** | Limited to simple triggers; can't integrate across tools |
| **AI Assistants** | Can describe what to do but can't actually create persistent automations |

### The Opportunity

OmniForge's conversational agent builder can bridge these gaps:

**For Individual Users (B2C)**:
1. User describes what they want automated in plain English
2. Chatbot creates an agent (determines if 1 or multiple skills needed)
3. Chatbot suggests public skills from community library or creates custom skills
4. Chatbot orchestrates multi-skill workflows automatically
5. Chatbot guides OAuth connection for integrations
6. Chatbot helps test and refine the agent
7. Agent persists and runs automatically

**For Organizations Serving Customers (B2B2C)**:
1. Organization creates agents for their specific use cases
2. Organization publishes agents to end customers with white-labeling
3. End customers onboard via branded portal (no technical expertise needed)
4. Organization manages agent updates centrally for all customers
5. Organization tracks usage for billing/analytics

**The chatbot becomes a "technical translator" that turns intentions into working agents, and the B2B2C model turns internal automations into customer-facing services.**

---

## User Journeys

### Journey 1: First-Time Agent Creation (Maya's Weekly Report)

**Goal**: Maya wants to automate her weekly status report from Notion

#### Phase 1: Discovery

```
Maya: "I spend way too much time creating weekly reports from our Notion
       project boards. Can you help me automate this?"

Chatbot: "Absolutely! I can create an agent that generates weekly reports
         from your Notion projects automatically.

         Before we start, I'll need to connect to your Notion workspace.
         This is a one-time setup that takes about 2 minutes.

         Ready to connect Notion?"

Maya: "Yes"

Chatbot: [Initiates OAuth flow - see Authentication section]
```

**Key Experience**: Maya doesn't encounter technical terms. She's asked a simple yes/no question about connecting Notion.

#### Phase 2: Connection

```
Chatbot: "Great! I'm opening Notion in a new tab. You'll see a screen asking
         which pages I can access.

         TIP: Select only the workspace with your project boards - you can
         always add more pages later.

         [Button: Open Notion Authorization]

         Let me know when you've approved the connection!"

[Maya clicks button, sees Notion OAuth screen, approves access]

Maya: "Done!"

Chatbot: "Connected! I can now see your workspace 'Acme Marketing'.

         I found these databases that look like project trackers:
         - Client Projects (42 items)
         - Internal Initiatives (8 items)
         - Archived Projects (156 items)

         Which ones should I include in your weekly report?"

Maya: "Client Projects and Internal Initiatives"
```

**Key Experience**: The chatbot explains what Maya will see before she sees it. It interprets her Notion structure and presents options in terms she uses.

#### Phase 3: Understanding Requirements

```
Chatbot: "Perfect! Now tell me about your weekly report:

         - What information should it include for each project?
         - Any specific format you use?
         - When do you need this report generated?"

Maya: "I need to see which projects had updates last week, what the current
       status is, and any blockers. I usually format it as a bulleted list
       grouped by client. I need it Monday mornings before my 9am meeting."

Chatbot: "Got it! Let me make sure I understand:

         YOUR WEEKLY REPORT WILL:
         - Check 'Client Projects' and 'Internal Initiatives' databases
         - Find projects updated in the last 7 days
         - For each project, show: current status and any blockers
         - Group projects by client
         - Format as a bulleted list
         - Generate every Monday at 8:30am (giving you 30 min before your meeting)

         Does this sound right?"

Maya: "Yes, but can you also include the project owner?"

Chatbot: "Absolutely! I'll include the project owner for each project.

         Updated summary:
         - Check 'Client Projects' and 'Internal Initiatives' databases
         - Find projects updated in the last 7 days
         - For each project, show: current status, blockers, AND project owner
         - Group projects by client
         - Format as a bulleted list
         - Generate every Monday at 8:30am

         Ready to create this skill?"

Maya: "Yes!"
```

**Key Experience**: The chatbot summarizes in Maya's language, not technical specs. It confirms understanding and easily incorporates refinements.

#### Phase 4: Agent Creation

```
Chatbot: "Creating your 'Weekly Project Report' agent...

         Done! Here's what I created:

         AGENT: Weekly Project Report
         - Runs: Every Monday at 8:30am
         - Uses: Your Notion connection
         - Output: Bulleted report grouped by client

         Before we activate it, let's test it with last week's data.
         Want me to run a test now?"

Maya: "Yes please"

Chatbot: "Running test...

         Here's what your report would have looked like this Monday:

         ---
         WEEKLY PROJECT REPORT - January 20, 2026

         ACME CORP
         - Website Redesign (Owner: Jake): On Track - Final review scheduled
         - Q1 Campaign (Owner: Sarah): At Risk - Waiting on client assets

         BRIGHTSIDE LLC
         - Social Strategy (Owner: Maya): Complete - Delivered Friday
         - Brand Refresh (Owner: Tom): On Track - No blockers

         INTERNAL
         - Team Training (Owner: Maya): On Track - Session scheduled Wed
         ---

         Does this look right?"

Maya: "Perfect! But can the At Risk projects be at the top?"

Chatbot: "Good idea! I'll sort projects so 'At Risk' and 'Blocked' appear
         first, then 'On Track', then 'Complete'.

         Want me to run another test with this change?"

Maya: "Yes"

[Chatbot runs test, shows updated format]

Maya: "That's great!"

Chatbot: "Your 'Weekly Project Report' agent is now active!

         It will run every Monday at 8:30am and create a new page in
         your 'Reports' folder in Notion.

         You can also run it anytime by saying 'Run my weekly report agent'.

         Anything else you'd like to automate?"
```

**Key Experience**: Maya sees exactly what her automation will produce before it goes live. She can refine it through conversation. The agent is activated with clear expectations.

---

### Journey 2: Editing an Agent & Using Public Skills (Derek's Customization)

**Goal**: Derek wants to modify a team agent to also post summaries to Slack

#### Phase 1: Finding the Agent and Discovering Public Skills

```
Derek: "I want to update our team's weekly report agent to also post
        a summary to Slack"

Chatbot: "I found the 'Weekly Project Report' agent shared with your team.

         Currently it:
         - Runs Monday at 8:30am
         - Creates a report in Notion

         You want to add Slack posting. I'll need to connect to your
         Slack workspace first. Ready?"

Derek: "I already connected Slack for another agent"

Chatbot: "You're right! You connected 'Acme Marketing' Slack workspace
         on January 15. I can use that connection.

         For posting to Slack, I found a public skill 'Slack Poster'
         (created by @sarah, used by 184 people) that's highly rated.

         Want to:
         A) Use this public skill (quick, proven to work)
         B) Create a custom Slack posting skill"

Derek: "Use the public one"

Chatbot: "Great choice! Which Slack channel should receive the summary?"

Derek: "#team-updates"

Chatbot: "Got it. The 'Slack Poster' skill supports different formats.
         What should the message include?

         Options:
         A) Full report (same as Notion)
         B) Just a summary (e.g., '5 projects updated, 1 at risk')
         C) Summary with link to full Notion report"

Derek: "C - summary with link"
```

#### Phase 2: Showing the Change

```
Chatbot: "Here's what will change:

         BEFORE:
         - Creates report in Notion

         AFTER:
         + Creates report in Notion
         + Posts summary to #team-updates:
           '5 projects updated this week (1 At Risk, 4 On Track).
           Full report: [link to Notion page]'

         Everything else stays the same (runs Monday 8:30am).

         Want to see a test before I save this?"

Derek: "Yes, run the test"

[Test runs, shows both Notion output and Slack message preview]

Chatbot: "Test complete! Here's the Slack message that would be posted:

         [Preview of Slack message with formatting]

         Save these changes?"

Derek: "Yes"

Chatbot: "Saved! I've created version 2 of 'Weekly Project Report'.

         VERSION HISTORY:
         - v1 (Jan 13): Original - Notion report only
         - v2 (Jan 25): Added Slack summary to #team-updates

         The updated skill will run Monday at 8:30am.

         Note: Since this is a team skill, all team members will get
         the Slack message too. Want to notify them about this change?"
```

**Key Experience**: Derek sees exactly what's changing through a visual diff. Versioning happens automatically. Team implications are clearly communicated.

---

### Journey 3: Event-Driven Agent (Sandra's Meeting Prep)

**Goal**: Sandra wants meeting briefings created automatically when meetings are scheduled

#### Phase 1: Describing the Trigger

```
Sandra: "Can you help me prepare for my boss's meetings automatically?
         I want a briefing document created whenever a meeting is
         scheduled with an external person."

Chatbot: "Great idea! I can create an agent that automatically prepares
         briefing documents.

         To make this work, I need to know:
         1. How do I know when a new meeting is scheduled?
         2. What information should the briefing include?

         Let's start with #1. Where are your meetings tracked?"

Sandra: "We use Google Calendar, but I also log them in Notion"

Chatbot: "Since we're already connected to your Notion, let's use that!

         I can watch for new entries in a Notion database.
         Do you have a 'Meetings' database or similar?"

Sandra: "Yes, I add every external meeting to 'Executive Meetings' database"

Chatbot: "Perfect! I'll watch 'Executive Meetings' for new entries.

         When a new meeting is added, what should the briefing include?"

Sandra: "I want background on the person we're meeting - their company,
         their role, any previous meetings we've had with them, and
         recent news about their company"

Chatbot: "I understand! The briefing will include:
         - Contact information from the meeting entry
         - Company background
         - Their role and bio
         - Previous meeting history (from 'Executive Meetings')
         - Recent news about their company

         Where should I create the briefing document?"

Sandra: "In the same database, as a linked page to the meeting entry"

Chatbot: "Got it! Here's the complete agent:

         AGENT: Auto Meeting Briefing

         WHEN: New entry added to 'Executive Meetings'

         ACTIONS:
         1. Extract contact/company from meeting entry
         2. Search for previous meetings with same contact
         3. Look up company background and recent news
         4. Create briefing page linked to meeting entry

         BRIEFING INCLUDES:
         - Contact: name, role, company
         - Company: overview, recent news
         - History: past meetings (if any)

         Ready to create this?"
```

#### Phase 2: Testing Event-Driven Agents

```
Sandra: "Wait - how will I know it's working?"

Chatbot: "Great question! Here's how we'll test:

         OPTION A: Dry Run
         I'll pretend a meeting was just added and show you the
         briefing I would create. Nothing actually gets created.

         OPTION B: Real Test
         You add a test meeting to 'Executive Meetings' and I'll
         create a real briefing. You can delete both afterward.

         Which would you prefer?"

Sandra: "Let's do the dry run first"

Chatbot: "I'll use your most recent meeting entry as an example...

         Using: 'Meeting with John Smith, Acme Corp' from Jan 22

         HERE'S WHAT THE BRIEFING WOULD LOOK LIKE:

         ---
         MEETING BRIEFING: John Smith, Acme Corp
         January 22, 2026 at 2:00pm

         CONTACT
         - John Smith, VP of Operations
         - john.smith@acmecorp.com

         COMPANY: ACME CORP
         - Founded 2018, manufacturing equipment
         - 200 employees, HQ in Chicago

         RECENT NEWS
         - Jan 15: Announced expansion to European markets
         - Dec 20: Named 'Top Workplace' by Chicago Tribune

         PREVIOUS MEETINGS
         - Nov 3, 2025: Initial partnership discussion
         - Dec 1, 2025: Contract review
         ---

         Does this look helpful?"

Sandra: "Yes! But can you also include their LinkedIn profile if available?"

Chatbot: "Absolutely! I'll add a LinkedIn link when I can find one.

         Ready to activate 'Auto Meeting Briefing'?"

Sandra: "Yes, let's do it"

Chatbot: "Your agent is now active!

         HOW IT WORKS:
         - I check 'Executive Meetings' every 15 minutes for new entries
         - When I find one, I create a briefing within 5 minutes
         - The briefing appears as a linked page on the meeting entry

         FIRST TIME TIP:
         Add a test meeting now so you can see it work end-to-end.
         I'll let you know the moment the briefing is ready!

         Want me to walk you through adding a test meeting?"
```

**Key Experience**: Sandra understands exactly when and how the agent triggers. Dry run testing builds confidence without affecting real data. Clear explanation of the polling behavior.

---

### Journey 4: Sharing an Agent to Team (Derek)

```
Derek: "The meeting briefing agent Sandra created is really useful.
        Can we make it available to the whole team?"

Chatbot: "I can help you share 'Auto Meeting Briefing' with your team.

         Currently it's:
         - Private to Sandra
         - Uses Sandra's Notion connection
         - Watches Sandra's 'Executive Meetings' database

         To share with the team:
         1. Each team member needs their own Notion connection
         2. They'll configure which database to watch
         3. They'll choose where briefings are created

         Two options:

         OPTION A: Share as Template
         Team members get a copy they can customize.
         Changes don't sync between copies.

         OPTION B: Share as Team Agent
         One agent, everyone uses it. Admins can edit.
         Everyone needs access to the same database.

         Which fits your team better?"

Derek: "Template - everyone has their own databases"

Chatbot: "Got it! I'll share 'Auto Meeting Briefing' as a template.

         SHARING PREVIEW:
         - Agent name: Auto Meeting Briefing
         - Shared with: Acme Marketing Team (12 people)
         - Each person will: Connect their Notion, pick their database

         Share now?"

Derek: "Yes"

Chatbot: "Shared! Your team members will see 'Auto Meeting Briefing'
         in their Available Agents.

         When they activate it, I'll walk them through:
         1. Connecting their Notion (or using existing connection)
         2. Selecting their meetings database
         3. Running a test

         I'll notify #team-updates that a new agent template is available.

         Want to customize the announcement message?"
```

**Key Experience**: Clear distinction between template sharing (independence) and team agent (centralized). Automatic onboarding for recipients.

---

## Core Capabilities

### 1. Conversational Agent Creation

Users describe what they want automated in plain English. The chatbot:
- Asks clarifying questions to understand requirements
- Determines if the agent needs one skill or multiple skills
- Suggests relevant public skills from the community library
- Creates custom skills when needed
- Orchestrates multi-skill workflows (sequential, parallel, conditional)
- **Generates SKILL.md files following Claude Code's standard format**
  - Proper YAML frontmatter with required/optional fields
  - Clear, actionable instructions in natural language
  - Appropriate tool restrictions for security
  - Progressive disclosure pattern (core instructions + external docs)
- Handles edge cases the user might not have considered

**Public Skill Library**:
Community-contributed skills that can be reused when creating agents:
- "Medical Document Extractor" (extracts data from healthcare bills)
- "Invoice Data Extractor" (extracts line items from invoices)
- "Slack Poster" (posts messages to Slack channels)
- "Notion Weekly Summary" (generates summaries from Notion databases)
- "Email Sender" (sends templated emails)

**Agent Composition Intelligence**:
The chatbot automatically determines:
- Single-skill agents for simple tasks
- Multi-skill agents for complex workflows
- Orchestration strategy (sequential, parallel, conditional)
- Whether to reuse public skills or create custom ones

**Dynamic Skill Generation**:
For requirements not covered by public skills, the chatbot generates custom skill logic from scratch based on the conversation.

### 2. Guided Integration Authentication

When skills need external services:
- Chatbot initiates OAuth at the right moment in conversation
- Explains what permissions are being requested in plain English
- Stores credentials securely with proper scoping
- Reuses existing connections for new skills

**MVP Integration: Notion**
- OAuth 2.0 integration
- Workspace/page selection during connection
- Credential reuse across skills

**Future Integrations** (post-MVP):
- Slack (OAuth)
- Linear (OAuth)
- GitHub (OAuth)

### 3. Three Execution Models

#### On-Demand
```
User: "Run my weekly report agent"
Chatbot: [Executes agent, returns result]
```

#### Scheduled
```
During agent creation:
Chatbot: "When should this run?"
User: "Every Monday at 8:30am"
Chatbot: [Configures schedule, no separate UI needed]
```

Schedules are created conversationally. Users can say:
- "Every Monday at 9am"
- "Every hour during business hours"
- "First of each month"
- "Every Friday at 4pm Pacific"

#### Event-Driven (MVP)
- **Notion page created**: Agent runs when new page added to database
- **Webhook received**: Agent runs when external service sends webhook
- **Polling**: Agent checks for changes periodically (configurable interval)

### 4. Agent Editing with Visual Diff

When users want to modify agents:
- Chatbot shows current behavior (including all skills)
- User describes desired changes
- Chatbot determines if changes affect existing skills or require new skills
- Chatbot shows before/after comparison
- Changes are applied only after confirmation

```
BEFORE:
- Runs Monday at 8:30am
- Uses 1 skill: Notion Report Generator

AFTER:
+ Runs Monday at 8:30am
+ Uses 2 skills:
  1. Notion Report Generator (unchanged)
  2. Slack Poster (new, uses public skill)
```

### 5. Automatic Versioning

Every agent edit creates a new version:
- No manual version management
- Users can see version history
- Rollback through conversation ("undo my last change")
- Diffs between versions available on request
- Version updates can propagate to B2B2C deployments

### 6. Four-Tier Sharing Model

| Tier | Who Can Access | Use Case |
|------|----------------|----------|
| **Private** | Only creator | Personal automations |
| **Team** | Same tenant/organization | Team workflows |
| **Public** | Community library (skills only) | Contributed skills for reuse |
| **B2B2C Published** | End customers of parent org | White-labeled agent deployment |

Sharing is managed conversationally:
```
User: "Share this agent with my team"
Chatbot: [Explains implications, handles sharing]

User: "Publish this agent to our hospital network"
Chatbot: [Initiates B2B2C deployment flow]
```

### 7. Built-In Testing & Release Management

**Core Product Feature**: Testing is integrated directly into the conversational interface. Users test changes in-product, review results visually, and release when confident.

**Test-Before-Release Workflow**:
```
User: "Update the Insurance Filing Agent to support Cigna"

Bot: "I'll add Cigna support. Before releasing, let's test it.

     TEST OPTIONS:

     1. QUICK TEST (5 mins)
        I'll test with sample data to verify basic functionality

     2. FULL TEST (30 mins)
        Test with real data from your Notion, all edge cases

     3. PILOT TEST (48 hours)
        Deploy to 2 pilot hospitals, monitor real usage

     Which test level?"

User: "Full test"

Bot: "Running full test suite...

     [Progress bar: Testing 1/5 - Extracting patient data...]
     [Progress bar: Testing 2/5 - Filling Cigna form...]
     [Progress bar: Testing 3/5 - Validating fields...]
     [Progress bar: Testing 4/5 - Checking API integration...]
     [Progress bar: Testing 5/5 - End-to-end workflow...]

     TEST RESULTS:

     ‚úÖ PASSED (4/5 tests)
     ‚ö†Ô∏è  WARNING (1/5 tests)

     DETAILS:
     ‚úÖ Patient data extraction: PASSED
     ‚úÖ Cigna form filling: PASSED
     ‚úÖ Field validation: PASSED
     ‚ö†Ô∏è  API integration: WARNING - Rate limit detected (498/500 requests)
     ‚úÖ End-to-end workflow: PASSED

     RECOMMENDATION:
     Tests passed but you're near Cigna API rate limit.
     Consider upgrading quota before full deployment.

     OPTIONS:
     A) Release now (with warning noted)
     B) Fix API quota issue first
     C) Run pilot test with 2 hospitals

     What would you like to do?"

User: "Release now"

Bot: "Deploying v2.0 with Cigna support...

     DEPLOYMENT STRATEGY:
     Stage 1: 10% (250 hospitals) - Now
     Stage 2: 50% (1,250 hospitals) - In 48 hours if Stage 1 success
     Stage 3: 100% (2,500 hospitals) - In 96 hours if Stage 2 success

     I'll monitor each stage and alert you if issues arise.

     Deployment started. You'll get updates in real-time."
```

**Visual Test Results Dashboard**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ TEST RESULTS: Insurance Filing Agent v2.0      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                 ‚îÇ
‚îÇ ‚úÖ 4 Passed    ‚ö†Ô∏è  1 Warning    ‚ùå 0 Failed    ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ
‚îÇ ‚îÇ ‚úÖ Patient Data Extraction       ‚îÇ 2.1s      ‚îÇ
‚îÇ ‚îÇ    ‚Ä¢ Extracted 15 fields         ‚îÇ           ‚îÇ
‚îÇ ‚îÇ    ‚Ä¢ All required fields present ‚îÇ           ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ
‚îÇ ‚îÇ ‚úÖ Cigna Form Filling            ‚îÇ 1.8s      ‚îÇ
‚îÇ ‚îÇ    ‚Ä¢ All fields populated        ‚îÇ           ‚îÇ
‚îÇ ‚îÇ    ‚Ä¢ Group Number validated      ‚îÇ           ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ
‚îÇ ‚îÇ ‚ö†Ô∏è  Cigna API Integration        ‚îÇ 0.9s      ‚îÇ
‚îÇ ‚îÇ    ‚Ä¢ Connection successful       ‚îÇ           ‚îÇ
‚îÇ ‚îÇ    ‚Ä¢ Rate limit: 498/500 (99.6%) ‚îÇ           ‚îÇ
‚îÇ ‚îÇ    ‚ö†Ô∏è  Near rate limit threshold ‚îÇ           ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ [View Detailed Logs] [Run Again] [Release]     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Test Modes**:

| Test Mode | Duration | Coverage | Use Case |
|-----------|----------|----------|----------|
| **Quick Test** | 5 mins | Basic functionality | Quick validation during development |
| **Full Test** | 30 mins | All features + edge cases | Pre-release validation |
| **Pilot Test** | 24-72 hrs | Real usage with select customers | High-confidence validation |
| **Load Test** | 1 hour | Scale testing (1000+ concurrent) | B2B2C deployments |
| **Regression Test** | 15 mins | Ensure no existing features broken | After each change |

**Automated Test Generation**:
```
Bot: "I've created an agent with 3 skills. Let me generate tests automatically...

     AUTO-GENERATED TESTS:

     Skill 1: Notion Data Extractor
     ‚úì Test database connection
     ‚úì Test data extraction with sample data
     ‚úì Test with empty database
     ‚úì Test with missing fields

     Skill 2: Data Transformer
     ‚úì Test data transformation logic
     ‚úì Test with edge cases (nulls, special chars)
     ‚úì Test output format

     Skill 3: Slack Notifier
     ‚úì Test Slack connection
     ‚úì Test message formatting
     ‚úì Test with long messages

     Total: 11 tests generated

     Run all tests now?"
```

**Interactive Test Debugging**:
```
User: "Why did the Cigna API test fail?"

Bot: "Let me show you the test failure details:

     TEST: Cigna API Integration
     STATUS: ‚ö†Ô∏è  WARNING
     TIMESTAMP: 2026-01-25 10:23:47

     REQUEST:
     POST https://api.cigna.com/v1/claims
     Body: {
       "patient_id": "P12345",
       "group_number": "GRP001",
       ...
     }

     RESPONSE:
     Status: 429 (Rate Limit Exceeded)
     Headers: {
       "X-Rate-Limit-Remaining": "2",
       "X-Rate-Limit-Reset": "2026-01-25T10:30:00Z"
     }

     EXPLANATION:
     You've made 498 requests out of 500/hour limit.
     The test succeeded but you're near the limit.

     RECOMMENDATION:
     Contact Cigna to increase rate limit to 1000/hour
     before deploying to all 2,500 hospitals.

     Want me to draft an email to Cigna requesting quota increase?"
```

### 8. Test-Driven Development Flow

**Built into every agent change**:

```
1. User makes change
   ‚Üì
2. Bot auto-generates tests
   ‚Üì
3. Bot runs tests (user sees real-time progress)
   ‚Üì
4. User reviews test results visually
   ‚Üì
5. If tests pass ‚Üí User releases
   If tests fail ‚Üí User fixes and re-tests
```

**Example: Adding New Skill to Agent**

```
User: "Add a skill to send email notifications after filing insurance"

Bot: "I'll add an Email Notifier skill to your Insurance Filing Agent.

     CURRENT AGENT:
     ‚Ä¢ Skill 1: Medical Document Extractor
     ‚Ä¢ Skill 2: Cigna Form Filler

     UPDATED AGENT:
     ‚Ä¢ Skill 1: Medical Document Extractor
     ‚Ä¢ Skill 2: Cigna Form Filler
     ‚Ä¢ Skill 3: Email Notifier (NEW)

     Running tests to verify the new skill integrates correctly...

     [Testing in progress...]

     TEST RESULTS:

     ‚úÖ Existing skills still work (regression test passed)
     ‚úÖ New email skill works independently
     ‚úÖ Data flows correctly: Extractor ‚Üí Filler ‚Üí Email
     ‚úÖ Email template renders correctly

     All tests passed! Safe to release.

     RELEASE OPTIONS:
     A) Release to sandbox only (test yourself first)
     B) Release to pilot (2 hospitals)
     C) Release to all 2,500 hospitals (staged rollout)

     What would you like to do?"

User: "Release to sandbox"

Bot: "Released to your sandbox!

     TEST IT YOURSELF:
     1. Go to sandbox.hospitalchain.com
     2. Process a test claim
     3. Check your email for notification

     When you're satisfied, say 'release to pilot' to deploy to hospitals."
```

**Comparison Testing (Before/After)**:
```
Bot: "You've updated the Cigna form filler. Let me test before and after:

     COMPARISON TEST:

     Version 1.0 (Current):
     ‚îú‚îÄ Claims processed: 100 sample claims
     ‚îú‚îÄ Success rate: 94%
     ‚îú‚îÄ Avg time: 3.2s
     ‚îî‚îÄ Failures: 6 (missing Group Number)

     Version 2.0 (Your Update):
     ‚îú‚îÄ Claims processed: 100 same sample claims
     ‚îú‚îÄ Success rate: 99% ‚úì (+5%)
     ‚îú‚îÄ Avg time: 2.8s ‚úì (-0.4s faster)
     ‚îî‚îÄ Failures: 1 (unrelated Notion timeout)

     SUMMARY:
     ‚úÖ 5% improvement in success rate
     ‚úÖ 12% faster processing
     ‚úÖ Fixed Group Number issue

     Your update is performing better! Release?"
```

**Test Coverage Metrics**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ TEST COVERAGE: Insurance Filing Agent  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                         ‚îÇ
‚îÇ Code Coverage:        87% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    ‚îÇ
‚îÇ Feature Coverage:     100% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   ‚îÇ
‚îÇ Edge Case Coverage:   73% ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ UNTESTED SCENARIOS:                     ‚îÇ
‚îÇ ‚ö†Ô∏è  Notion connection failure          ‚îÇ
‚îÇ ‚ö†Ô∏è  Extremely large bills (>100 items) ‚îÇ
‚îÇ ‚ö†Ô∏è  Special characters in patient names‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ [Generate Missing Tests] [View Details]‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Continuous Testing (Post-Release)**:
```
After releasing v2.0 to 250 hospitals:

Bot: "Stage 1 deployment is live. Running continuous tests...

     LIVE TESTING (every 15 mins):
     ‚úÖ Health check: All 250 hospitals online
     ‚úÖ Success rate: 96.2% (above 95% threshold)
     ‚úÖ Avg response time: 2.9s (within range)
     ‚úÖ Error rate: 3.8% (normal variance)

     Stage 1 is performing well! Continue to Stage 2?"

User: "Yes"

Bot: "Deploying to Stage 2 (1,250 hospitals)...
     Continuous testing will monitor all 1,500 hospitals (Stage 1 + 2)."
```

### 9. Test Environments

**Sandbox (Personal Testing)**:
```
User: "Create a sandbox for testing"

Bot: "Created sandbox environment!

     Your sandbox:
     URL: sandbox.hospitalchain.com
     Data: Copy of your production Notion data (last 30 days)
     Credentials: Uses your personal integrations

     You can:
     ‚Ä¢ Test changes without affecting hospitals
     ‚Ä¢ Process fake claims
     ‚Ä¢ See exactly what hospitals will experience

     Sandbox ready! Make changes and test freely."
```

**Staging (Pre-Production)**:
```
User: "Create a staging environment for my team to review"

Bot: "Created staging environment!

     Staging:
     URL: staging.hospitalchain.com
     Data: Mirror of production (synced hourly)
     Users: Your team (5 people)

     Your team can test v2.0 before releasing to hospitals.

     Invited team members will receive access link."
```

**Production (Live Customers)**:
```
Production:
URL: agents.hospitalchain.com
Users: 2,500 hospitals
Version: v1.0 (stable)
```

### 10. Release Approval Workflow

**Built-in approval gates**:
```
User: "Release v2.0 to all hospitals"

Bot: "Before releasing to 2,500 hospitals, I need approvals:

     RELEASE CHECKLIST:

     Tests:
     ‚úÖ Quick test passed
     ‚úÖ Full test passed
     ‚úÖ Pilot test passed (2 hospitals, 48 hours)

     Reviews:
     ‚è≥ VP of Operations approval (pending)
     ‚è≥ CTO approval (pending)

     Notifications:
     ‚úÖ Email sent to all hospitals
     ‚úÖ In-app banners scheduled

     I'll notify you when approvals are complete.
     Estimated release time: Once approvals received + 2 hours"

---

Later:

Bot: "‚úÖ All approvals received!

     VP of Operations: Approved ‚úì
     CTO: Approved ‚úì

     Ready to release v2.0 to 2,500 hospitals.

     Final confirmation: Release now?"

User: "Yes"

Bot: "Releasing v2.0...

     Stage 1: 250 hospitals (now)
     Stage 2: 1,250 hospitals (in 48 hours)
     Stage 3: 2,500 hospitals (in 96 hours)

     I'll update you at each stage."
```

### 7. B2B2C Agent Publishing

Organizations can publish agents to their customers:
- **White-Label Portal**: Branded portal for end customers
- **Embedded Widget**: Embed agents in existing applications
- **API Access**: Programmatic agent execution
- **Multi-Tenant Isolation**: Each end customer's data isolated
- **Centralized Management**: Update agents for all customers at once
- **Usage Analytics**: Track usage per end customer for billing
- **Onboarding Flow**: Guided setup for each end customer
- **Built-In Testing**: Test before release, compare versions, continuous monitoring
- **Release Management**: Approvals, staged rollouts, rollback capabilities

---

## Success Criteria

### User Outcomes

| Metric | Target | How We Measure |
|--------|--------|----------------|
| **Skill Creation Success** | 80% of started creations complete successfully | Funnel analysis: start to activation |
| **Time to First Skill** | Under 10 minutes for template-based | Session timing from first message to activation |
| **Zero-Help Success** | 70% complete without contacting support | Support ticket correlation |
| **Return Usage** | 60% create a second skill within 30 days | Cohort analysis |
| **Edit Success** | 90% of edit requests complete successfully | Funnel from edit request to confirmation |

### User Satisfaction

| Metric | Target | How We Measure |
|--------|--------|----------------|
| **Confidence Score** | 8+ out of 10 "I trust this will work" | In-app survey after creation |
| **Clarity Score** | 8+ out of 10 "I understood what would happen" | Post-activation survey |
| **NPS for Feature** | 50+ | Feature-specific NPS |

### Business Outcomes

| Metric | Target | Rationale |
|--------|--------|-----------|
| **Premium Conversion** | 15% of free users convert after using agent builder | Core premium differentiator |
| **Agent Retention** | 70% of created agents still active after 30 days | Shows lasting value |
| **Team Expansion** | 40% of team agents lead to new team member signups | Viral growth vector |
| **Community Contribution** | 100 public skills in first 90 days | Ecosystem health |
| **B2B2C Adoption** | 10% of Tier 2 customers publish agents to end customers | New revenue stream |
| **B2B2C Scale** | Average 25 end customers per published agent | Network effects |

### Technical Outcomes

| Metric | Target | Rationale |
|--------|--------|-----------|
| **Agent Execution Success** | 95% execute without errors | Reliability is critical for trust |
| **Response Time** | Chatbot responds in < 3 seconds | Conversational fluidity |
| **OAuth Completion** | 85% complete OAuth flow | Integration friction |
| **Schedule Reliability** | 99.9% of scheduled agents run on time | Users depend on schedules |

### Testing & Release Outcomes

| Metric | Target | Rationale |
|--------|--------|-----------|
| **Test Before Release** | 90% of changes tested before deployment | Catch issues early |
| **Test Execution Time** | Full test completes in < 30 minutes | Fast feedback loop |
| **Pilot Test Adoption** | 70% of B2B2C deployments use pilot testing | Validate at scale safely |
| **Rollback Rate** | <5% of releases require rollback | High-quality releases |
| **Staged Rollout Success** | 98% of staged rollouts complete without issues | Gradual deployment works |
| **Test Coverage** | 80% code coverage for generated agents | Comprehensive testing |

---

## User Stories

### Epic: First Agent Creation

#### US-1: Public Skill Discovery
**As** Maya (non-technical user)
**I want** to see what public skills are available when creating my agent
**So that** I can leverage proven solutions instead of starting from scratch

**Acceptance Criteria**:
- Chatbot suggests relevant public skills based on user's description
- Skills show usage stats ("used by 500+ people")
- Skills have clear, jargon-free descriptions
- User can choose to use public skill or create custom
- User can browse skills by category ("Document Extraction", "Notifications", "Data Sync")

**Conversation Example**:
```
Maya: "I want to create an agent that generates weekly reports from Notion"

Chatbot: "I found a public skill 'Notion Weekly Summary' created by @derek
         and used by 247 people. It generates weekly summaries from Notion databases.

         Want to:
         A) Use this public skill (quick setup, proven to work)
         B) Create a custom skill tailored to your needs"

Maya: "Use the public one"

Chatbot: "Great! I'll create your agent using 'Notion Weekly Summary'.
         Let me customize it for your databases..."
```

---

#### US-2: Plain English Agent Description
**As** Maya (non-technical user)
**I want** to describe my automation in my own words
**So that** I don't have to learn technical terminology

**Acceptance Criteria**:
- Chatbot understands natural language descriptions
- Chatbot asks clarifying questions in non-technical language
- Chatbot automatically determines if agent needs one or multiple skills
- Technical concepts are translated to user-friendly terms
- User never sees: webhook, API, OAuth, JSON, YAML, cron, regex, orchestration

**Conversation Example**:
```
Maya: "I want to know when projects are running late and get notified on Slack"

Chatbot: "I can create an agent that monitors your projects! Tell me more:

         - What does 'running late' mean for you?
           (e.g., 3 days before deadline, past deadline)
         - Which Slack channel should get the notification?"

[Behind the scenes: Chatbot determines this needs 2 skills:
 1. Deadline Checker (scans Notion)
 2. Slack Notifier (sends alerts)
 User never sees this decomposition]
```

---

#### US-3: Guided OAuth Connection
**As** Maya (non-technical user)
**I want** connecting to Notion to be simple and clear
**So that** I don't get confused by authorization screens

**Acceptance Criteria**:
- Chatbot explains what will happen before OAuth redirect
- OAuth happens in a new tab, not disrupting conversation
- Chatbot confirms when connection is complete
- If connection fails, chatbot explains why in plain terms

**Conversation Example**:
```
Chatbot: "I'll open Notion in a new tab. You'll see a screen asking
         which workspaces I can access.

         SELECT: The workspace with your projects
         SKIP: Personal spaces you don't want to share

         [Button: Connect Notion]

         Click the button when you're ready!"
```

---

#### US-4: Preview Before Activation
**As** Sandra (apprehensive user)
**I want** to see exactly what my agent will do before it's active
**So that** I can trust it won't do anything unexpected

**Acceptance Criteria**:
- Every agent can be tested before activation
- Test shows real output using real (or simulated) data
- For multi-skill agents, test shows output of each step
- Clear distinction between test and live execution
- User explicitly confirms activation

**Conversation Example**:
```
Chatbot: "Before activating, let's test with real data.

         I'll run your agent using last week's data. This is
         a DRY RUN - nothing will actually be created.

         [Runs test]

         Step 1: Extracted data from Notion ‚úì
         Step 2: Generated report ‚úì

         Here's what would have been created:
         [Shows output]

         Look good? Say 'activate' to turn it on."
```

---

### Epic: Agent Editing

#### US-5: Describe Changes Conversationally
**As** Derek (team lead)
**I want** to change my agent by describing what's different
**So that** I don't have to understand the underlying configuration

**Acceptance Criteria**:
- User describes change in natural language
- Chatbot determines if change requires adding/removing/modifying skills
- Chatbot suggests public skills if new functionality needed
- Changes applied only after explicit confirmation
- Original agent preserved until confirmation

---

#### US-6: Visual Change Comparison
**As** Derek (team lead)
**I want** to see exactly what will change before I confirm
**So that** I can verify the change is what I intended

**Acceptance Criteria**:
- Before/after shown in clear visual format
- Changes highlighted (skills added, removed, modified)
- Shows which skills are public vs custom
- Non-changed elements shown for context
- User can reject and refine

---

#### US-7: Automatic Version History
**As** Sandra (apprehensive user)
**I want** previous versions saved automatically
**So that** I can undo changes if something goes wrong

**Acceptance Criteria**:
- Every edit creates a new version automatically
- Version history visible on request
- Rollback available through conversation
- Versions include timestamp and change summary
- For B2B2C agents, version updates can propagate to end customers

---

### Epic: Agent Execution

#### US-8: On-Demand Execution
**As** Maya (operations manager)
**I want** to run my agent whenever I need it
**So that** I'm not limited to schedules

**Acceptance Criteria**:
- User can trigger any agent through conversation
- Execution status shown in real-time for each skill
- Results displayed in chat when complete
- Errors explained in plain language

---

#### US-9: Scheduled Execution
**As** Maya (operations manager)
**I want** my agent to run automatically on a schedule
**So that** I don't have to remember to trigger it

**Acceptance Criteria**:
- Schedule set through conversation (not separate UI)
- Natural language schedule parsing ("every Monday at 9am")
- Schedule confirmation shown after creation
- Schedule can be changed conversationally

---

#### US-10: Event-Triggered Execution
**As** Sandra (executive assistant)
**I want** my agent to run when something happens in Notion
**So that** I get immediate results without waiting

**Acceptance Criteria**:
- Agents can trigger on Notion page creation
- Agents can trigger on Notion page updates (polling)
- Trigger conditions explained clearly
- User understands polling delays (not instant)
- Multi-skill agents run all steps when triggered

---

### Epic: Agent Sharing

#### US-11: Share with Team
**As** Derek (team lead)
**I want** to share my agent with my team
**So that** everyone benefits from my automation

**Acceptance Criteria**:
- Sharing initiated through conversation
- Clear explanation of what team members will see
- Choice between template (copies) and team agent (shared)
- Notification sent to team about new agent

---

#### US-12: Discover Team Agents
**As** Maya (team member)
**I want** to see agents my team has shared
**So that** I can use automations others have created

**Acceptance Criteria**:
- Team agents visible in agent discovery
- Clear indication of who created/shared
- Shows which public skills the agent uses
- Easy to activate shared agents
- Prompted to connect required integrations

---

#### US-13: Contribute Public Skills
**As** Derek (power user)
**I want** to share reusable skills with the OmniForge community
**So that** others can use them when creating their agents

**Acceptance Criteria**:
- Clear publishing flow for skills (not full agents)
- Skill anonymized (no personal data)
- Description and usage instructions required
- Creator attribution maintained
- Skill appears in public library for agent creation

---

### Epic: Testing & Release Management

#### US-TEST-1: Test Before Release
**As** Derek (team lead)
**I want** to test agent changes in the product before releasing
**So that** I don't deploy broken agents to my team or customers

**Acceptance Criteria**:
- Test options presented after making changes (Quick, Full, Pilot)
- Visual test results dashboard showing pass/fail/warnings
- Ability to drill into test failures for debugging
- Compare before/after performance metrics
- Auto-generated tests for new skills
- Regression tests ensure existing functionality still works

**Conversation Example**:
```
User: "Add Cigna support to Insurance Filing Agent"

Bot: "I'll add Cigna support. Let's test it first.

     TEST OPTIONS:
     ‚Ä¢ Quick Test (5 mins) - Basic functionality
     ‚Ä¢ Full Test (30 mins) - All features + edge cases
     ‚Ä¢ Pilot Test (48 hrs) - Real usage with 2 hospitals

     Which test?"

User: "Full test"

Bot: "Running full test...

     ‚úÖ 4/5 tests passed
     ‚ö†Ô∏è  1/5 warning (API rate limit near threshold)

     Safe to release with noted warning.

     Release now?"
```

---

#### US-TEST-2: Sandbox Testing Environment
**As** Maya (operations manager)
**I want** a personal sandbox to test changes myself
**So that** I can see exactly what my team/customers will experience

**Acceptance Criteria**:
- One-click sandbox creation
- Sandbox mirrors production data (last 30 days)
- Can process test transactions safely
- Changes in sandbox don't affect production
- Clear indication when in sandbox vs production

---

#### US-TEST-3: Staged Release with Monitoring
**As** Derek (managing 2,500 hospital customers)
**I want** to release changes gradually with automatic monitoring
**So that** I catch issues early before affecting all customers

**Acceptance Criteria**:
- Staged rollout strategy (10% ‚Üí 50% ‚Üí 100%)
- Real-time monitoring dashboard during rollout
- Automatic pause if success rate drops below threshold
- Ability to manually pause/resume at any stage
- Continuous testing of deployed stages
- Notifications at each stage completion

---

#### US-TEST-4: Release Approval Workflow
**As** VP of Operations (managing compliance)
**I want** to approve releases before they deploy to customers
**So that** I maintain governance over production changes

**Acceptance Criteria**:
- Configure approval requirements per agent
- Test results included in approval request
- Approvers see impact analysis (# customers affected)
- Email notification to approvers
- Release only proceeds after required approvals
- Approval audit log

---

#### US-TEST-5: Test Comparison (Before/After)
**As** Derek (team lead)
**I want** to compare test results before and after my changes
**So that** I can verify improvements and catch regressions

**Acceptance Criteria**:
- Side-by-side comparison of old vs new version
- Metrics: success rate, avg time, error types
- Process same test data through both versions
- Highlight improvements and regressions
- Recommend release based on comparison

**Conversation Example**:
```
Bot: "COMPARISON TEST:

     v1.0 (Current):  94% success, 3.2s avg
     v2.0 (Updated): 99% success, 2.8s avg ‚úì

     ‚úÖ 5% improvement in success rate
     ‚úÖ 12% faster processing

     Your update is performing better! Release?"
```

---

#### US-TEST-6: Continuous Post-Release Testing
**As** Derek (managing production deployment)
**I want** continuous testing after release
**So that** I detect issues immediately in production

**Acceptance Criteria**:
- Automated health checks every 15 minutes
- Monitor success rate, response time, error rate
- Alert if metrics fall outside normal range
- Compare production metrics to pre-release tests
- Automatic rollback trigger if severe issues detected

---

## Integration Architecture: Notion

### OAuth Flow

```
1. User says "I need to connect Notion"

2. Chatbot displays:
   "I'll open Notion authorization in a new tab.
    Select the workspace with your projects.
    [Button: Connect Notion]"

3. User clicks button:
   - New tab opens to: https://api.notion.com/v1/oauth/authorize
   - Parameters: client_id, redirect_uri, response_type=code
   - Scopes: read/write pages, read databases

4. User authorizes in Notion:
   - Selects workspace and pages
   - Clicks "Allow Access"

5. Notion redirects to OmniForge callback:
   - OmniForge receives authorization code
   - Exchanges code for access token
   - Stores token securely (encrypted, per-user)

6. Chatbot confirms:
   "Connected! I can now access 'Acme Marketing' workspace.
    This connection will be used for all your Notion skills."
```

### Credential Reuse

- One Notion connection per user
- Connection used across all user's Notion skills
- User can revoke connection (affects all skills)
- Connection status shown when creating skills

```
User starts new skill:

Chatbot: "This skill needs Notion access.
         You're already connected to 'Acme Marketing' workspace.

         Want to use this connection or connect a different workspace?"
```

### Notion API Usage

Skills interact with Notion through:
- **Read Databases**: List items, filter, sort
- **Read Pages**: Get page content and properties
- **Create Pages**: Add new pages to databases
- **Update Pages**: Modify properties and content
- **Query**: Search across workspace

All API calls are made server-side with stored credentials.

### Error Handling

| Error | User Message | Action |
|-------|--------------|--------|
| Token expired | "Your Notion connection needs to be refreshed" | Re-authenticate |
| Page not found | "I can't find that page anymore. Was it deleted?" | Prompt to reconfigure |
| Permission denied | "I don't have permission to access that page" | Prompt to re-authorize |
| Rate limited | "Notion is busy. I'll try again in a moment" | Automatic retry |
| API error | "Something went wrong with Notion. Here's what happened: [plain explanation]" | Log and retry |

---

## Non-Goals (MVP)

### Not Building

| Feature | Reason | When to Consider |
|---------|--------|------------------|
| **GitHub Integration** | Lower priority for non-technical users | After Notion, Linear, Slack |
| **Complex Conditional Logic** | Adds complexity for marginal benefit | V2 based on user demand |
| **Multi-Step Skill Chaining** | Increases complexity significantly | V2 with proven single-skill usage |
| **Real-time Event Triggers** | Webhook infrastructure complexity | V2 with established polling |
| **Custom Scripts in Skills** | Security and complexity concerns | V2 with sandboxing |
| **Skill Marketplace Payments** | Business model complexity | Post-community traction |
| **Mobile App** | Focus on web experience first | After web is proven |
| **Offline Skills** | Requires local execution | Out of scope |

### Explicitly Deferred

- **AI-Generated Skill Suggestions**: Proactively suggesting skills based on user behavior
- **Advanced Test Authoring**: Let users write custom test scripts (beyond auto-generated)
- **Performance Profiling**: Detailed CPU/memory/network profiling during tests
- **Import from Other Platforms**: Migrating Zapier/Make automations
- **Advanced Debugging Tools**: Step-through execution, breakpoints, time-travel debugging
- **Multi-Language Skills**: Skills in languages other than English
- **Load Testing UI**: Visual load testing dashboard (MVP: basic load test only)
- **Test Replay**: Record production executions and replay as tests

---

## Open Questions

### User Experience

1. **How much hand-holding is too much?**
   - Risk of being patronizing to semi-technical users
   - Need user research to calibrate guidance level

2. **What happens when skill creation fails?**
   - How do we communicate failure without technical jargon?
   - What recovery options do we offer?

3. **How do users discover skills they didn't know they needed?**
   - Proactive suggestions vs. on-demand discovery
   - Balance between helpful and intrusive

### Technical

4. **How do we handle Notion schema changes?**
   - User renames database columns after skill creation
   - Need graceful degradation and user notification

5. **What's the polling frequency for event triggers?**
   - Balance between responsiveness and API rate limits
   - User expectations vs. technical constraints

6. **How do we version skills with external dependencies?**
   - Notion API changes, OAuth scope changes
   - Migration strategy for existing skills

### Business

7. **How do we moderate public skill submissions?**
   - Quality standards, security review
   - Community moderation vs. staff review

8. **What's the conversion trigger for free users?**
   - When do we gate features behind premium?
   - Balance between value demonstration and conversion

### B2B2C Deployment

9. **How do we price B2B2C deployments?**
   - Per-agent pricing vs per-end-customer vs execution-based?
   - Different pricing for white-label portal vs embedded vs API?

10. **What level of customization do Tier 2 customers get?**
    - Can they modify agent logic for specific end customers?
    - How much branding control (full theme vs just logo/colors)?

11. **How do we handle support for B2B2C deployments?**
    - Does Tier 2 customer support their end customers?
    - Or do end customers contact OmniForge directly?
    - SLA requirements for B2B2C deployments?

12. **Security and compliance for B2B2C?**
    - HIPAA compliance for healthcare use cases?
    - Data residency requirements (EU, US, etc.)?
    - Audit logs and compliance reporting for Tier 2 customers?

### Testing & Release

13. **How long should tests take?**
    - Quick test: 5 min target, but is that too slow?
    - Full test: 30 min target, acceptable for pre-release?
    - Balance between thoroughness and speed?

14. **What's the default rollout strategy?**
    - Should we default to staged rollout for all B2B2C deployments?
    - Or let users choose per release?
    - Force staged rollout for >100 end customers?

15. **How do we generate meaningful tests automatically?**
    - Static analysis of skill code?
    - Learn from production execution patterns?
    - User provides sample data during agent creation?

16. **Rollback data handling?**
    - If we rollback, what happens to data created by new version?
    - Do we migrate data back? Leave it? Warn users?

---

## Appendix A: SKILL.md Generation (Claude Code Format)

The chatbot generates SKILL.md files following **Claude Code's standard format** to ensure compatibility and proper progressive disclosure.

### Required Format

```markdown
---
# === REQUIRED FIELDS (Claude Code Standard) ===
name: notion-weekly-report
description: Generate weekly status reports from Notion project databases

# === OPTIONAL FIELDS (Claude Code Standard) ===
allowed-tools:
  - ExternalAPI
  - Read
  - Write
model: claude-sonnet-4-5
context: inherit
user-invocable: false

# === OMNIFORGE EXTENSIONS ===
priority: 0
tags:
  - notion
  - reporting
  - automation
---

# Notion Weekly Report Generator

Generate weekly status reports from Notion project databases.

## Prerequisites

Before generating a report:
1. Verify Notion API credentials are configured
2. Confirm target databases are accessible
3. Validate date range parameters

## Report Generation Process

1. **Query Notion API**
   - Use ExternalAPI tool to fetch database entries
   - Filter: `last_edited_time` > 7 days ago
   - Databases: "Client Projects", "Internal Initiatives"

2. **Extract Project Data**
   For each project, extract:
   - Project name
   - Current status
   - Owner
   - Blockers (if any)
   - Last update date

3. **Format Report**
   - Group projects by client
   - Sort by status: At Risk ‚Üí On Track ‚Üí Complete
   - Use bulleted markdown format
   - Include generation timestamp

4. **Write Output**
   - Create file: `reports/weekly-{YYYY-MM-DD}.md`
   - Format: Markdown

## Report Template

```
WEEKLY PROJECT REPORT - {date}

{CLIENT_NAME}
- {Project}: {Status} - {Summary}
  Owner: {Owner}
  Blockers: {Blockers or "None"}

[Repeat for each client]
```

## Error Handling

- **API fails**: Retry up to 3 times with exponential backoff
- **Database not found**: Log error, skip that database, continue
- **No updates found**: Generate report with "No updates this week"
- **Authentication fails**: Return clear error to user

## Reference

- See [notion-api.md](docs/notion-api.md) for API documentation
- See [report-formats.md](docs/report-formats.md) for customization options
```

### Field Definitions

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| **name** | string | ‚úÖ Yes | Unique skill identifier (kebab-case) |
| **description** | string | ‚úÖ Yes | One-line description for agent discovery (max 80 chars) |
| **allowed-tools** | string[] | ‚ùå No | Tool allowlist for security (omit = all tools) |
| **model** | string | ‚ùå No | Preferred model (defaults to agent's model) |
| **context** | enum | ‚ùå No | `inherit` (default) or `fork` for sub-agent |
| **user-invocable** | boolean | ‚ùå No | Can user invoke with `/skill-name`? (default: false) |
| **priority** | number | ‚ùå No | Override priority for conflicts (OmniForge extension) |
| **tags** | string[] | ‚ùå No | Categorization tags (OmniForge extension) |

### Chatbot Generation Rules

When generating SKILL.md files, the chatbot MUST:

1. **Use Standard Frontmatter**
   - ‚úÖ Always include: `name`, `description`
   - ‚úÖ Include `allowed-tools` for security (restrict to minimum needed)
   - ‚úÖ Set `user-invocable: false` (agent uses skill internally)
   - ‚ùå Never include: `schedule`, `trigger`, `created-by` (these go in agent.json)

2. **Write Clear Instructions**
   - Use imperative voice ("Query the API", "Extract data", "Format output")
   - Provide specific steps in numbered/bulleted lists
   - Include error handling guidance
   - Reference external docs for details

3. **Follow Progressive Disclosure**
   - Keep SKILL.md under 10KB (core instructions only)
   - Put detailed API docs in `docs/` folder
   - Put examples in `examples/` folder
   - Reference with relative links: `[api-docs.md](docs/api-docs.md)`

4. **Set Appropriate Tool Restrictions**
   - Only allow tools the skill actually needs
   - Examples:
     - Notion integration: `["ExternalAPI", "Read", "Write"]`
     - File operations: `["Read", "Write", "Glob", "Bash"]`
     - Reporting only: `["Read", "Write"]`

5. **Use Proper Naming**
   - Format: `{integration}-{action}-{object}`
   - Examples: `notion-weekly-report`, `slack-post-message`, `github-create-issue`
   - Use kebab-case
   - Be specific (avoid generic names like "report")

### Separation of Concerns

**SKILL.md** (Execution):
- Skill instructions for the agent
- Tool restrictions
- Model preferences
- Core procedural logic

**agent.json** (Metadata):
- Agent name, description, status
- Trigger configuration: `scheduled`, `on-demand`, `event-triggered`
- Schedule: `"0 8 30 * * MON"`
- Skill orchestration: `sequential`, `parallel`, `conditional`
- UI rendering metadata
- Created by, created at, version tracking

---

## Appendix B: Error Messages Guide

All error messages follow these principles:
- No technical jargon
- Clear explanation of what happened
- Actionable next step
- Offer to help

| Situation | Message |
|-----------|---------|
| OAuth failed | "I couldn't connect to Notion. Let's try again - sometimes it just needs a second attempt. [Button: Try Again]" |
| Database not found | "I can't find the 'Client Projects' database. Did it get renamed or moved? Tell me the new name and I'll update your skill." |
| Skill execution failed | "Your weekly report skill ran into a problem: I couldn't access one of the project pages. This might be a temporary Notion issue. Want me to try again?" |
| Schedule parsing failed | "I didn't quite understand '8:30ish on Mondays'. Could you say it like 'Monday at 8:30am'?" |
| Permission denied | "I don't have permission to create pages in 'Reports'. You might need to update the Notion connection to include that folder. [Button: Update Connection]" |

---

## Evolution Notes

### 2026-01-25 v2.1 (Claude Code Format Compliance)

**Update**: Aligned all SKILL.md generation with Claude Code's standard format for compatibility and best practices.

**Changes**:

1. **Standardized SKILL.md Frontmatter**:
   - Required fields: `name`, `description`
   - Optional fields: `allowed-tools`, `model`, `context`, `user-invocable`
   - OmniForge extensions: `priority`, `tags`
   - Removed non-standard fields: `schedule`, `trigger`, `created-by`, `source`, `author` (moved to agent.json)

2. **Updated SKILL.md Examples**:
   - All examples now follow Claude Code format
   - Clear separation between SKILL.md (execution) and agent.json (metadata)
   - Proper progressive disclosure pattern demonstrated

3. **Added Claude Code Compliance Section**:
   - Explains why Claude Code format is required
   - Documents format requirements and chatbot responsibilities
   - References official Claude Code documentation

4. **Enhanced Appendix A**:
   - Complete SKILL.md generation guidelines
   - Field definitions table
   - Chatbot generation rules (naming, descriptions, tool selection, instructions)
   - Validation checklist
   - Anti-patterns to avoid

**Rationale**:
- Ensures compatibility with industry-standard skill format
- Enables portability across OmniForge deployments
- Provides clarity for developers familiar with Claude Code
- Maintains clean separation of concerns (execution vs. metadata)

**References**:
- Claude Code System Prompts: https://github.com/Piebald-AI/claude-code-system-prompts
- OmniForge Skills System Spec: `/specs/skills-system-spec.md`

---

### 2026-01-25 v2.0 (Agent-First Architecture + B2B2C)

**Major Update**: Transformed from skill-centric to agent-first architecture with B2B2C deployment model.

**Core Architectural Changes**:

1. **Agent-First Model**: Users create agents (not skills directly). Agents contain 1+ skills orchestrated automatically by the chatbot.

2. **Public Skill Library**: Community-contributed reusable skills that can be used when creating agents.

3. **Intelligent Orchestration**: Chatbot determines if agents need single or multiple skills, and how to orchestrate them (sequential, parallel, conditional).

4. **B2B2C Deployment**: Organizations can publish agents to their customers with:
   - White-labeled portals
   - Embedded widgets
   - API access
   - Multi-tenant isolation
   - Centralized management
   - Usage analytics

5. **Dual Storage Format**: agent.json for frontend rendering + SKILL.md files for execution.

6. **Built-In Testing & Release Management**: Testing is a first-class product feature:
   - Quick/Full/Pilot test modes directly in chat
   - Visual test results dashboards
   - Sandbox and staging environments
   - Staged rollout strategies (canary, blue-green, A/B)
   - Automatic and manual rollback
   - Release approval workflows
   - Continuous post-release testing

**New Use Cases**:
- Insurance Filing Agent (healthcare): Multi-skill with public skill reuse
- PO/Invoice Matching Agent (finance): Parallel + sequential orchestration
- B2B2C deployments: Hospital chains, accounting firms, SaaS platforms

**Updated Sharing Model**:
- Private (personal)
- Team (organization)
- Public (skills only, not full agents)
- B2B2C Published (white-labeled deployment to end customers)

**Next Steps**:
1. Technical planning for agent orchestration engine
2. Design public skill library architecture
3. Design B2B2C multi-tenant isolation
4. Define agent.json schema and storage strategy
5. Create complex multi-skill use case examples
6. Design white-labeling and embedding capabilities

---

### 2026-01-25 v1.0 (Initial Draft)

Created specification based on requirements confirmed with user:
- Scope: Conversational skill creation for premium chatbot platform
- MVP Integration: Notion (with OAuth)
- Target Users: Completely non-technical users needing maximum guidance
- Execution Models: On-demand, scheduled, event-driven (all in scope)
- Sharing Model: Private, team, public (all in scope)

**Key Design Decisions**:

1. **Conversational-First**: Every interaction happens through chat. No separate UI for schedules, sharing, or configuration.

2. **Maximum Hand-Holding**: Target user can't distinguish webhook from API. Every technical concept must be translated.

3. **Template + Dynamic Hybrid**: Templates for common patterns (fast path), dynamic generation for custom needs (complete path).

4. **Test Before Activate**: Users must see skill output before it goes live. Builds trust and catches errors early.

5. **Builds on Existing Infrastructure**: Generates SKILL.md files compatible with existing skills system. Not a new system.
